{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supervised Learning with H2O - Classification\n",
    "\n",
    "## H2O\n",
    "\n",
    "H2O is a fully open source, distributed in-memory machine learning platform with linear scalability. H2O supports the most widely used statistical & machine learning algorithms including gradient boosted machines, generalized linear models, deep learning and more.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installation\n",
    "H2O offers an R package that can be installed from CRAN and a python package that can be installed from PyPI. In this session, I shall be working with only the Python implementation. Also, you may want to look at the [documentation](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html#install-in-python) for complete details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Testing installation\n",
    "Every new python session begins by initializing a connection between the python client and the H2O cluster. A cluster is a group of H2O nodes that work together; when a job is submitted to a cluster, all the nodes in the cluster work on a portion of the job.\n",
    "\n",
    "To check if everything is in place, open your Jupyter Notebooks and type in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>8 hours 10 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Kolkata</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.1.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>18 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_parulpandey_9oe7qo</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.050 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         8 hours 10 mins\n",
       "H2O_cluster_timezone:       Asia/Kolkata\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.1.2\n",
       "H2O_cluster_version_age:    18 days\n",
       "H2O_cluster_name:           H2O_from_python_parulpandey_9oe7qo\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.050 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.3 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By default, H2O instance uses all the cores and about 25% of the system’s memory. However, in case you wish to allocate it a fixed chunk of memory, you can specify it in the init function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objective\n",
    "\n",
    "\n",
    "We’re going to use machine learning with H2O to predict whether or not a loan holder will default. To do this, we are going to build two classification models: a Linear model, and a Gradient Boosting Machine model, to predict whether or not a loan will be delinquent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Import H2O and other libraries that will be used in this tutorial \n",
    "import h2o\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Import the Estimators\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "\n",
    "#Import h2o grid search \n",
    "import h2o.grid \n",
    "from h2o.grid.grid_search import H2OGridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing the dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#Import the dataset \n",
    "loan_level = h2o.import_file(\"https://s3.amazonaws.com/data.h2o.ai/DAI-Tutorials/loan_level_500k.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have our dataset, we will explore some concepts and then do some exploration of the data and prepare it for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  CREDIT_SCORE</th><th style=\"text-align: right;\">  FIRST_PAYMENT_DATE</th><th>FIRST_TIME_HOMEBUYER_FLAG  </th><th style=\"text-align: right;\">  MATURITY_DATE</th><th style=\"text-align: right;\">  METROPOLITAN_STATISTICAL_AREA</th><th style=\"text-align: right;\">  MORTGAGE_INSURANCE_PERCENTAGE</th><th style=\"text-align: right;\">  NUMBER_OF_UNITS</th><th>OCCUPANCY_STATUS  </th><th style=\"text-align: right;\">  ORIGINAL_COMBINED_LOAN_TO_VALUE</th><th style=\"text-align: right;\">  ORIGINAL_DEBT_TO_INCOME_RATIO</th><th style=\"text-align: right;\">  ORIGINAL_UPB</th><th style=\"text-align: right;\">  ORIGINAL_LOAN_TO_VALUE</th><th style=\"text-align: right;\">  ORIGINAL_INTEREST_RATE</th><th>CHANNEL  </th><th>PREPAYMENT_PENALTY_MORTGAGE_FLAG  </th><th>PRODUCT_TYPE  </th><th>PROPERTY_STATE  </th><th>PROPERTY_TYPE  </th><th style=\"text-align: right;\">  POSTAL_CODE</th><th>LOAN_SEQUENCE_NUMBER  </th><th>LOAN_PURPOSE  </th><th style=\"text-align: right;\">  ORIGINAL_LOAN_TERM</th><th style=\"text-align: right;\">  NUMBER_OF_BORROWERS</th><th>SELLER_NAME  </th><th>SERVICER_NAME  </th><th>PREPAID  </th><th>DELINQUENT  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">           669</td><td style=\"text-align: right;\">              200206</td><td>N                          </td><td style=\"text-align: right;\">         202901</td><td style=\"text-align: right;\">                            nan</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               80</td><td style=\"text-align: right;\">                             33</td><td style=\"text-align: right;\">        162000</td><td style=\"text-align: right;\">                      80</td><td style=\"text-align: right;\">                   7.12 </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WV              </td><td>SF             </td><td style=\"text-align: right;\">        26100</td><td>F199Q1000004          </td><td>P             </td><td style=\"text-align: right;\">                 320</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           732</td><td style=\"text-align: right;\">              199904</td><td>N                          </td><td style=\"text-align: right;\">         202903</td><td style=\"text-align: right;\">                          17140</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               25</td><td style=\"text-align: right;\">                             10</td><td style=\"text-align: right;\">         53000</td><td style=\"text-align: right;\">                      25</td><td style=\"text-align: right;\">                   6.5  </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td style=\"text-align: right;\">        45200</td><td>F199Q1000005          </td><td>N             </td><td style=\"text-align: right;\">                 360</td><td style=\"text-align: right;\">                    1</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           679</td><td style=\"text-align: right;\">              200208</td><td>N                          </td><td style=\"text-align: right;\">         202902</td><td style=\"text-align: right;\">                          15940</td><td style=\"text-align: right;\">                             30</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               91</td><td style=\"text-align: right;\">                             48</td><td style=\"text-align: right;\">        133000</td><td style=\"text-align: right;\">                      91</td><td style=\"text-align: right;\">                   6.75 </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td style=\"text-align: right;\">        44700</td><td>F199Q1000007          </td><td>P             </td><td style=\"text-align: right;\">                 319</td><td style=\"text-align: right;\">                    1</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           721</td><td style=\"text-align: right;\">              200209</td><td>N                          </td><td style=\"text-align: right;\">         202902</td><td style=\"text-align: right;\">                          38060</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               39</td><td style=\"text-align: right;\">                             13</td><td style=\"text-align: right;\">        174000</td><td style=\"text-align: right;\">                      39</td><td style=\"text-align: right;\">                   6.625</td><td>T        </td><td>N                                 </td><td>FRM           </td><td>AZ              </td><td>SF             </td><td style=\"text-align: right;\">        85200</td><td>F199Q1000013          </td><td>N             </td><td style=\"text-align: right;\">                 318</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           618</td><td style=\"text-align: right;\">              200210</td><td>N                          </td><td style=\"text-align: right;\">         202902</td><td style=\"text-align: right;\">                          10420</td><td style=\"text-align: right;\">                             25</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               85</td><td style=\"text-align: right;\">                             24</td><td style=\"text-align: right;\">        122000</td><td style=\"text-align: right;\">                      85</td><td style=\"text-align: right;\">                   6.375</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td style=\"text-align: right;\">        44200</td><td>F199Q1000015          </td><td>N             </td><td style=\"text-align: right;\">                 317</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           738</td><td style=\"text-align: right;\">              200211</td><td>N                          </td><td style=\"text-align: right;\">         202903</td><td style=\"text-align: right;\">                          10420</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               73</td><td style=\"text-align: right;\">                             44</td><td style=\"text-align: right;\">        218000</td><td style=\"text-align: right;\">                      73</td><td style=\"text-align: right;\">                   6    </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td style=\"text-align: right;\">        44300</td><td>F199Q1000016          </td><td>P             </td><td style=\"text-align: right;\">                 317</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           761</td><td style=\"text-align: right;\">              200211</td><td>N                          </td><td style=\"text-align: right;\">         202904</td><td style=\"text-align: right;\">                            nan</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               73</td><td style=\"text-align: right;\">                             31</td><td style=\"text-align: right;\">        138000</td><td style=\"text-align: right;\">                      73</td><td style=\"text-align: right;\">                   6.375</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>SC              </td><td>PU             </td><td style=\"text-align: right;\">        29500</td><td>F199Q1000017          </td><td>P             </td><td style=\"text-align: right;\">                 318</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           707</td><td style=\"text-align: right;\">              200211</td><td>N                          </td><td style=\"text-align: right;\">         202903</td><td style=\"text-align: right;\">                          33340</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               60</td><td style=\"text-align: right;\">                             57</td><td style=\"text-align: right;\">        136000</td><td style=\"text-align: right;\">                      60</td><td style=\"text-align: right;\">                   6.25 </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WI              </td><td>SF             </td><td style=\"text-align: right;\">        53000</td><td>F199Q1000018          </td><td>C             </td><td style=\"text-align: right;\">                 317</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           760</td><td style=\"text-align: right;\">              200211</td><td>N                          </td><td style=\"text-align: right;\">         202903</td><td style=\"text-align: right;\">                          33340</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               63</td><td style=\"text-align: right;\">                             30</td><td style=\"text-align: right;\">         79000</td><td style=\"text-align: right;\">                      63</td><td style=\"text-align: right;\">                   6.125</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WI              </td><td>SF             </td><td style=\"text-align: right;\">        53000</td><td>F199Q1000019          </td><td>N             </td><td style=\"text-align: right;\">                 317</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           691</td><td style=\"text-align: right;\">              200302</td><td>N                          </td><td style=\"text-align: right;\">         202901</td><td style=\"text-align: right;\">                          15940</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               65</td><td style=\"text-align: right;\">                             25</td><td style=\"text-align: right;\">        130000</td><td style=\"text-align: right;\">                      65</td><td style=\"text-align: right;\">                   5.875</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td style=\"text-align: right;\">        44700</td><td>F199Q1000023          </td><td>P             </td><td style=\"text-align: right;\">                 312</td><td style=\"text-align: right;\">                    2</td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:500137\n",
      "Cols:27\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>CREDIT_SCORE     </th><th>FIRST_PAYMENT_DATE  </th><th>FIRST_TIME_HOMEBUYER_FLAG  </th><th>MATURITY_DATE     </th><th>METROPOLITAN_STATISTICAL_AREA  </th><th>MORTGAGE_INSURANCE_PERCENTAGE  </th><th>NUMBER_OF_UNITS    </th><th>OCCUPANCY_STATUS  </th><th>ORIGINAL_COMBINED_LOAN_TO_VALUE  </th><th>ORIGINAL_DEBT_TO_INCOME_RATIO  </th><th>ORIGINAL_UPB      </th><th>ORIGINAL_LOAN_TO_VALUE  </th><th>ORIGINAL_INTEREST_RATE  </th><th>CHANNEL  </th><th>PREPAYMENT_PENALTY_MORTGAGE_FLAG  </th><th>PRODUCT_TYPE  </th><th>PROPERTY_STATE  </th><th>PROPERTY_TYPE  </th><th>POSTAL_CODE       </th><th>LOAN_SEQUENCE_NUMBER  </th><th>LOAN_PURPOSE  </th><th>ORIGINAL_LOAN_TERM  </th><th>NUMBER_OF_BORROWERS  </th><th>SELLER_NAME  </th><th>SERVICER_NAME  </th><th>PREPAID  </th><th>DELINQUENT  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int              </td><td>int                 </td><td>enum                       </td><td>int               </td><td>int                            </td><td>int                            </td><td>int                </td><td>enum              </td><td>int                              </td><td>int                            </td><td>int               </td><td>int                     </td><td>real                    </td><td>enum     </td><td>enum                              </td><td>enum          </td><td>enum            </td><td>enum           </td><td>int               </td><td>string                </td><td>enum          </td><td>int                 </td><td>int                  </td><td>enum         </td><td>enum           </td><td>enum     </td><td>enum        </td></tr>\n",
       "<tr><td>mins   </td><td>300.0            </td><td>199901.0            </td><td>                           </td><td>202402.0          </td><td>10180.0                        </td><td>0.0                            </td><td>1.0                </td><td>                  </td><td>6.0                              </td><td>1.0                            </td><td>8000.0            </td><td>6.0                     </td><td>4.625                   </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>600.0             </td><td>NaN                   </td><td>              </td><td>301.0               </td><td>1.0                  </td><td>             </td><td>               </td><td>         </td><td>            </td></tr>\n",
       "<tr><td>mean   </td><td>712.5362124215458</td><td>200025.4309519192   </td><td>                           </td><td>203023.19587233098</td><td>30777.824739295047             </td><td>7.744531707523455              </td><td>1.0288902574110144 </td><td>                  </td><td>76.05357071446284                </td><td>32.917540518705394             </td><td>136493.48478516893</td><td>75.7107140572013        </td><td>7.182686863799317       </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>55490.857138286694</td><td>NaN                   </td><td>              </td><td>359.8554696013292   </td><td>1.6302946648262613   </td><td>             </td><td>               </td><td>         </td><td>            </td></tr>\n",
       "<tr><td>maxs   </td><td>839.0            </td><td>201103.0            </td><td>                           </td><td>204101.0          </td><td>49740.0                        </td><td>55.0                           </td><td>4.0                </td><td>                  </td><td>180.0                            </td><td>65.0                           </td><td>578000.0          </td><td>100.0                   </td><td>11.5                    </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>99900.0           </td><td>NaN                   </td><td>              </td><td>362.0               </td><td>2.0                  </td><td>             </td><td>               </td><td>         </td><td>            </td></tr>\n",
       "<tr><td>sigma  </td><td>54.79126197408833</td><td>109.81554141521666  </td><td>                           </td><td>110.38418855758627</td><td>11333.401144164463             </td><td>12.046545969492563             </td><td>0.21839057355939087</td><td>                  </td><td>15.139986048512696               </td><td>11.111799994455252             </td><td>60968.74306564563 </td><td>14.93771708896868       </td><td>0.5799408623980542      </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>29505.38225880303 </td><td>NaN                   </td><td>              </td><td>1.90825071041874    </td><td>0.48272535304031633  </td><td>             </td><td>               </td><td>         </td><td>            </td></tr>\n",
       "<tr><td>zeros  </td><td>0                </td><td>0                   </td><td>                           </td><td>0                 </td><td>0                              </td><td>309979                         </td><td>0                  </td><td>                  </td><td>0                                </td><td>0                              </td><td>0                 </td><td>0                       </td><td>0                       </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>0                 </td><td>0                     </td><td>              </td><td>0                   </td><td>0                    </td><td>             </td><td>               </td><td>         </td><td>            </td></tr>\n",
       "<tr><td>missing</td><td>2711             </td><td>0                   </td><td>0                          </td><td>0                 </td><td>70149                          </td><td>51048                          </td><td>3                  </td><td>0                 </td><td>13                               </td><td>14929                          </td><td>0                 </td><td>9                       </td><td>0                       </td><td>0        </td><td>0                                 </td><td>0             </td><td>0               </td><td>0              </td><td>31                </td><td>0                     </td><td>0             </td><td>0                   </td><td>247                  </td><td>0            </td><td>0              </td><td>0        </td><td>0           </td></tr>\n",
       "<tr><td>0      </td><td>669.0            </td><td>200206.0            </td><td>N                          </td><td>202901.0          </td><td>nan                            </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>80.0                             </td><td>33.0                           </td><td>162000.0          </td><td>80.0                    </td><td>7.12                    </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WV              </td><td>SF             </td><td>26100.0           </td><td>F199Q1000004          </td><td>P             </td><td>320.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>1      </td><td>732.0            </td><td>199904.0            </td><td>N                          </td><td>202903.0          </td><td>17140.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>25.0                             </td><td>10.0                           </td><td>53000.0           </td><td>25.0                    </td><td>6.5                     </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td>45200.0           </td><td>F199Q1000005          </td><td>N             </td><td>360.0               </td><td>1.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>2      </td><td>679.0            </td><td>200208.0            </td><td>N                          </td><td>202902.0          </td><td>15940.0                        </td><td>30.0                           </td><td>1.0                </td><td>O                 </td><td>91.0                             </td><td>48.0                           </td><td>133000.0          </td><td>91.0                    </td><td>6.75                    </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td>44700.0           </td><td>F199Q1000007          </td><td>P             </td><td>319.0               </td><td>1.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>3      </td><td>721.0            </td><td>200209.0            </td><td>N                          </td><td>202902.0          </td><td>38060.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>39.0                             </td><td>13.0                           </td><td>174000.0          </td><td>39.0                    </td><td>6.625                   </td><td>T        </td><td>N                                 </td><td>FRM           </td><td>AZ              </td><td>SF             </td><td>85200.0           </td><td>F199Q1000013          </td><td>N             </td><td>318.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>4      </td><td>618.0            </td><td>200210.0            </td><td>N                          </td><td>202902.0          </td><td>10420.0                        </td><td>25.0                           </td><td>1.0                </td><td>O                 </td><td>85.0                             </td><td>24.0                           </td><td>122000.0          </td><td>85.0                    </td><td>6.375                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td>44200.0           </td><td>F199Q1000015          </td><td>N             </td><td>317.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>5      </td><td>738.0            </td><td>200211.0            </td><td>N                          </td><td>202903.0          </td><td>10420.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>73.0                             </td><td>44.0                           </td><td>218000.0          </td><td>73.0                    </td><td>6.0                     </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td>44300.0           </td><td>F199Q1000016          </td><td>P             </td><td>317.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>6      </td><td>761.0            </td><td>200211.0            </td><td>N                          </td><td>202904.0          </td><td>nan                            </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>73.0                             </td><td>31.0                           </td><td>138000.0          </td><td>73.0                    </td><td>6.375                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>SC              </td><td>PU             </td><td>29500.0           </td><td>F199Q1000017          </td><td>P             </td><td>318.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>7      </td><td>707.0            </td><td>200211.0            </td><td>N                          </td><td>202903.0          </td><td>33340.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>60.0                             </td><td>57.0                           </td><td>136000.0          </td><td>60.0                    </td><td>6.25                    </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WI              </td><td>SF             </td><td>53000.0           </td><td>F199Q1000018          </td><td>C             </td><td>317.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>8      </td><td>760.0            </td><td>200211.0            </td><td>N                          </td><td>202903.0          </td><td>33340.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>63.0                             </td><td>30.0                           </td><td>79000.0           </td><td>63.0                    </td><td>6.125                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WI              </td><td>SF             </td><td>53000.0           </td><td>F199Q1000019          </td><td>N             </td><td>317.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>9      </td><td>691.0            </td><td>200302.0            </td><td>N                          </td><td>202901.0          </td><td>15940.0                        </td><td>0.0                            </td><td>1.0                </td><td>O                 </td><td>65.0                             </td><td>25.0                           </td><td>130000.0          </td><td>65.0                    </td><td>5.875                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td>44700.0           </td><td>F199Q1000023          </td><td>P             </td><td>312.0               </td><td>2.0                  </td><td>Other sellers</td><td>Other servicers</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loan_level.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The total number of rows in our dataset is 500,137, and the total number of features or columns is 27. Additionally, you will get a sense of the spread of each of your columns, the column type, as well as the number of missing and zero values in your dataset.\n",
    "\n",
    "Let's take a quick look at the response column by checking the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>DELINQUENT  </th><th style=\"text-align: right;\">  Count</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FALSE       </td><td style=\"text-align: right;\"> 482146</td></tr>\n",
       "<tr><td>TRUE        </td><td style=\"text-align: right;\">  17991</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_level[\"DELINQUENT\"].table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As you can see, we have a very imbalanced dataset, as only 3.6% of the samples are TRUE labels, meaning that only 3.6% of the samples in the dataset have been labeled as DELINQUENT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train Test Split\n",
    "\n",
    "Since we have a large enough dataset, we will split our dataset into three sets, and we will call them train, valid, and test. We will treat the test set as if it were some unseen data in which we want to make predictions, and we will use the valid set for validation purposes and to tune all our models. We will not use the test set until the end of the tutorial to check the final scores of our models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train, valid, test = loan_level.split_frame([0.7, 0.15], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can check the distribution of the data split by checking the number of rows in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:350268 valid:74971 test:74898\n"
     ]
    }
   ],
   "source": [
    "print(\"train:%d valid:%d test:%d\" % (train.nrows, valid.nrows, test.nrows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assigning Target and Predictor Variables\n",
    "Next, we need to choose our predictors, or x variable, and our response or y variable. For the H2O-3 estimators, we do not use the actual data frame; instead, we use strings containing the name of the columns in our dataset.\n",
    "\n",
    "For our y variable, we will choose DELINQUENT because we want to predict whether or not a loan will default. For the x variable, we will choose all but four features. One is the feature that we will predict, and then PREPAID and PREPAYMENT_PENALTY_MORTGAGE_FLAG because they are clear indicators if a loan is or is not delinquent and we will not have the information at the time deciding whether to give a loan or not. In machine learning terms, introducing these types of features is called leakage. And lastly, PRODUCT_TYPE because that’s a constant value for every row, meaning all samples have the same value; therefore, this feature will not have any predictive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y = \"DELINQUENT\"\n",
    "\n",
    "ignore = [\"DELINQUENT\", \"PREPAID\", \"PREPAYMENT_PENALTY_MORTGAGE_FLAG\", \"PRODUCT_TYPE\"] \n",
    "\n",
    "x = list(set(train.names) - set(ignore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LOAN_PURPOSE', 'LOAN_SEQUENCE_NUMBER', 'NUMBER_OF_UNITS', 'MATURITY_DATE', 'ORIGINAL_LOAN_TERM', 'SELLER_NAME', 'ORIGINAL_INTEREST_RATE', 'FIRST_PAYMENT_DATE', 'CREDIT_SCORE', 'PROPERTY_TYPE', 'METROPOLITAN_STATISTICAL_AREA', 'MORTGAGE_INSURANCE_PERCENTAGE', 'PROPERTY_STATE', 'ORIGINAL_LOAN_TO_VALUE', 'OCCUPANCY_STATUS', 'CHANNEL', 'POSTAL_CODE', 'ORIGINAL_UPB', 'FIRST_TIME_HOMEBUYER_FLAG', 'ORIGINAL_DEBT_TO_INCOME_RATIO', 'NUMBER_OF_BORROWERS', 'ORIGINAL_COMBINED_LOAN_TO_VALUE', 'SERVICER_NAME']\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Build a [GLM](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html)\n",
    "\n",
    "Now that we have our train, valid, and test sets, as well as our x and y variables defined, we can start building models! We will start with an H2O Generalized Linear Model (GLM). A GLM fits a generalized linear model, specified by a response variable, a set of predictors, and a description of the error distribution. Since we have a binomial classification problem, we have to specify the family, in this case, it will be binomial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "glm = H2OGeneralizedLinearEstimator(family = \"binomial\", seed=42, model_id = 'default_glm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we will train our GLM model. To do so, we just use the .train() function. In the train function, we need to specify the predictors (x), the response (y), the training set (train), and a validation frame, if you have one. In our case, we have our valid set, which we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parulpandey/anaconda3/lib/python3.7/site-packages/h2o/estimators/estimator_base.py:200: RuntimeWarning: Dropping bad and constant columns: [LOAN_SEQUENCE_NUMBER]\n",
      "  warnings.warn(mesg[\"message\"], RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "CPU times: user 49.6 ms, sys: 8.39 ms, total: 58 ms\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%time glm.train(x = x, y = y, training_frame = train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You have now built and trained a GLM! If you type the name of your model in a new cell and run it, H2O will give you a complete summary of your model. You will see your model’s metrics on the training and validation set. From the model details, you will see a short summary with the parameters of your model, the metrics of your model, the confusion matrix, maximum matrices at different thresholds, a Gains/Lift table, and the scoring history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  default_glm\n",
      "\n",
      "\n",
      "GLM Model: summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>link</th>\n",
       "      <th>regularization</th>\n",
       "      <th>number_of_predictors_total</th>\n",
       "      <th>number_of_active_predictors</th>\n",
       "      <th>number_of_iterations</th>\n",
       "      <th>training_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>binomial</td>\n",
       "      <td>logit</td>\n",
       "      <td>Elastic Net (alpha = 0.5, lambda = 6.626E-5 )</td>\n",
       "      <td>161</td>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "      <td>py_4_sid_b63e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       family   link                                 regularization  \\\n",
       "0    binomial  logit  Elastic Net (alpha = 0.5, lambda = 6.626E-5 )   \n",
       "\n",
       "   number_of_predictors_total number_of_active_predictors  \\\n",
       "0                         161                          87   \n",
       "\n",
       "   number_of_iterations training_frame  \n",
       "0                     5  py_4_sid_b63e  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.031429596152939394\n",
      "RMSE: 0.17728394217452237\n",
      "LogLoss: 0.12332208377108474\n",
      "Null degrees of freedom: 350267\n",
      "Residual degrees of freedom: 350180\n",
      "Null deviance: 108932.13150363766\n",
      "Residual deviance: 86391.55927666061\n",
      "AIC: 86567.55927666061\n",
      "AUC: 0.8502065574882316\n",
      "AUCPR: 0.20627736272382008\n",
      "Gini: 0.7004131149764632\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1280457299765312: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>321921.0</td>\n",
       "      <td>15686.0</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>(15686.0/337607.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>7889.0</td>\n",
       "      <td>4772.0</td>\n",
       "      <td>0.6231</td>\n",
       "      <td>(7889.0/12661.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>329810.0</td>\n",
       "      <td>20458.0</td>\n",
       "      <td>0.0673</td>\n",
       "      <td>(23575.0/350268.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FALSE     TRUE   Error                 Rate\n",
       "0  FALSE  321921.0  15686.0  0.0465   (15686.0/337607.0)\n",
       "1   TRUE    7889.0   4772.0  0.6231     (7889.0/12661.0)\n",
       "2  Total  329810.0  20458.0  0.0673   (23575.0/350268.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.128046</td>\n",
       "      <td>0.288173</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.066761</td>\n",
       "      <td>0.386494</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.217579</td>\n",
       "      <td>0.288088</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.975799</td>\n",
       "      <td>0.963851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.547351</td>\n",
       "      <td>0.399068</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.975799</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.110350</td>\n",
       "      <td>0.267474</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.039248</td>\n",
       "      <td>0.772256</td>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.036884</td>\n",
       "      <td>0.774164</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.975799</td>\n",
       "      <td>337606.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.975799</td>\n",
       "      <td>12661.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>337607.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>12661.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.975799</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.975799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold          value    idx\n",
       "0                        max f1   0.128046       0.288173  208.0\n",
       "1                        max f2   0.066761       0.386494  269.0\n",
       "2                  max f0point5   0.217579       0.288088  149.0\n",
       "3                  max accuracy   0.975799       0.963851    0.0\n",
       "4                 max precision   0.547351       0.399068   45.0\n",
       "5                    max recall   0.000943       1.000000  398.0\n",
       "6               max specificity   0.975799       0.999997    0.0\n",
       "7              max absolute_mcc   0.110350       0.267474  222.0\n",
       "8    max min_per_class_accuracy   0.039248       0.772256  307.0\n",
       "9   max mean_per_class_accuracy   0.036884       0.774164  311.0\n",
       "10                      max tns   0.975799  337606.000000    0.0\n",
       "11                      max fns   0.975799   12661.000000    0.0\n",
       "12                      max fps   0.000579  337607.000000  399.0\n",
       "13                      max tps   0.000943   12661.000000  398.0\n",
       "14                      max tnr   0.975799       0.999997    0.0\n",
       "15                      max fnr   0.975799       1.000000    0.0\n",
       "16                      max fpr   0.000579       1.000000  399.0\n",
       "17                      max tpr   0.000943       1.000000  398.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  3.61 %, avg score:  3.61 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.315158</td>\n",
       "      <td>10.543228</td>\n",
       "      <td>10.543228</td>\n",
       "      <td>0.381102</td>\n",
       "      <td>0.446474</td>\n",
       "      <td>0.381102</td>\n",
       "      <td>0.446474</td>\n",
       "      <td>0.105442</td>\n",
       "      <td>0.105442</td>\n",
       "      <td>954.322761</td>\n",
       "      <td>954.322761</td>\n",
       "      <td>0.099020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.231807</td>\n",
       "      <td>7.636930</td>\n",
       "      <td>9.090079</td>\n",
       "      <td>0.276049</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.328576</td>\n",
       "      <td>0.357386</td>\n",
       "      <td>0.076376</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>663.692966</td>\n",
       "      <td>809.007863</td>\n",
       "      <td>0.167885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030003</td>\n",
       "      <td>0.189192</td>\n",
       "      <td>6.160088</td>\n",
       "      <td>8.113415</td>\n",
       "      <td>0.222666</td>\n",
       "      <td>0.209040</td>\n",
       "      <td>0.293272</td>\n",
       "      <td>0.307937</td>\n",
       "      <td>0.061607</td>\n",
       "      <td>0.243425</td>\n",
       "      <td>516.008804</td>\n",
       "      <td>711.341510</td>\n",
       "      <td>0.221426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.160993</td>\n",
       "      <td>5.332368</td>\n",
       "      <td>7.418302</td>\n",
       "      <td>0.192747</td>\n",
       "      <td>0.174416</td>\n",
       "      <td>0.268146</td>\n",
       "      <td>0.274564</td>\n",
       "      <td>0.053313</td>\n",
       "      <td>0.296738</td>\n",
       "      <td>433.236765</td>\n",
       "      <td>641.830211</td>\n",
       "      <td>0.266365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.140669</td>\n",
       "      <td>4.517398</td>\n",
       "      <td>6.838088</td>\n",
       "      <td>0.163289</td>\n",
       "      <td>0.150331</td>\n",
       "      <td>0.247174</td>\n",
       "      <td>0.249716</td>\n",
       "      <td>0.045178</td>\n",
       "      <td>0.341916</td>\n",
       "      <td>351.739790</td>\n",
       "      <td>583.808814</td>\n",
       "      <td>0.302862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>0.087242</td>\n",
       "      <td>3.361581</td>\n",
       "      <td>5.099884</td>\n",
       "      <td>0.121510</td>\n",
       "      <td>0.109615</td>\n",
       "      <td>0.184344</td>\n",
       "      <td>0.179667</td>\n",
       "      <td>0.168075</td>\n",
       "      <td>0.509991</td>\n",
       "      <td>236.158061</td>\n",
       "      <td>409.988400</td>\n",
       "      <td>0.425366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150002</td>\n",
       "      <td>0.062797</td>\n",
       "      <td>2.344126</td>\n",
       "      <td>4.181281</td>\n",
       "      <td>0.084732</td>\n",
       "      <td>0.073801</td>\n",
       "      <td>0.151139</td>\n",
       "      <td>0.144378</td>\n",
       "      <td>0.117210</td>\n",
       "      <td>0.627202</td>\n",
       "      <td>134.412631</td>\n",
       "      <td>318.128062</td>\n",
       "      <td>0.495095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.048195</td>\n",
       "      <td>1.674472</td>\n",
       "      <td>3.554596</td>\n",
       "      <td>0.060526</td>\n",
       "      <td>0.054956</td>\n",
       "      <td>0.128487</td>\n",
       "      <td>0.122023</td>\n",
       "      <td>0.083722</td>\n",
       "      <td>0.710923</td>\n",
       "      <td>67.447154</td>\n",
       "      <td>255.459624</td>\n",
       "      <td>0.530083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300002</td>\n",
       "      <td>0.031474</td>\n",
       "      <td>1.151561</td>\n",
       "      <td>2.753585</td>\n",
       "      <td>0.041625</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>0.099533</td>\n",
       "      <td>0.094328</td>\n",
       "      <td>0.115157</td>\n",
       "      <td>0.826080</td>\n",
       "      <td>15.156123</td>\n",
       "      <td>175.358457</td>\n",
       "      <td>0.545807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399999</td>\n",
       "      <td>0.021722</td>\n",
       "      <td>0.623978</td>\n",
       "      <td>2.221194</td>\n",
       "      <td>0.022555</td>\n",
       "      <td>0.026217</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>0.077301</td>\n",
       "      <td>0.062396</td>\n",
       "      <td>0.888476</td>\n",
       "      <td>-37.602240</td>\n",
       "      <td>122.119423</td>\n",
       "      <td>0.506796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.015302</td>\n",
       "      <td>0.420186</td>\n",
       "      <td>1.860990</td>\n",
       "      <td>0.015188</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.067268</td>\n",
       "      <td>0.065501</td>\n",
       "      <td>0.042019</td>\n",
       "      <td>0.930495</td>\n",
       "      <td>-57.981442</td>\n",
       "      <td>86.099044</td>\n",
       "      <td>0.446640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600001</td>\n",
       "      <td>0.010848</td>\n",
       "      <td>0.289865</td>\n",
       "      <td>1.599135</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>0.056743</td>\n",
       "      <td>0.028987</td>\n",
       "      <td>0.959482</td>\n",
       "      <td>-71.013514</td>\n",
       "      <td>59.913493</td>\n",
       "      <td>0.372963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699998</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>0.196671</td>\n",
       "      <td>1.398787</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.050561</td>\n",
       "      <td>0.049939</td>\n",
       "      <td>0.019667</td>\n",
       "      <td>0.979149</td>\n",
       "      <td>-80.332858</td>\n",
       "      <td>39.878709</td>\n",
       "      <td>0.289619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.108996</td>\n",
       "      <td>1.237562</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.044734</td>\n",
       "      <td>0.044473</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.990048</td>\n",
       "      <td>-89.100449</td>\n",
       "      <td>23.756199</td>\n",
       "      <td>0.197177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899999</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.063976</td>\n",
       "      <td>1.107163</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.040020</td>\n",
       "      <td>0.039963</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>0.996446</td>\n",
       "      <td>-93.602438</td>\n",
       "      <td>10.716268</td>\n",
       "      <td>0.100063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.035542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.036147</td>\n",
       "      <td>0.036143</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-96.445799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold       lift  \\\n",
       "0       1                  0.010001         0.315158  10.543228   \n",
       "1       2                  0.020002         0.231807   7.636930   \n",
       "2       3                  0.030003         0.189192   6.160088   \n",
       "3       4                  0.040001         0.160993   5.332368   \n",
       "4       5                  0.050002         0.140669   4.517398   \n",
       "5       6                  0.100001         0.087242   3.361581   \n",
       "6       7                  0.150002         0.062797   2.344126   \n",
       "7       8                  0.200001         0.048195   1.674472   \n",
       "8       9                  0.300002         0.031474   1.151561   \n",
       "9      10                  0.399999         0.021722   0.623978   \n",
       "10     11                  0.500000         0.015302   0.420186   \n",
       "11     12                  0.600001         0.010848   0.289865   \n",
       "12     13                  0.699998         0.007533   0.196671   \n",
       "13     14                  0.799999         0.004969   0.108996   \n",
       "14     15                  0.899999         0.002843   0.063976   \n",
       "15     16                  1.000000         0.000103   0.035542   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0         10.543228       0.381102  0.446474                  0.381102   \n",
       "1          9.090079       0.276049  0.268298                  0.328576   \n",
       "2          8.113415       0.222666  0.209040                  0.293272   \n",
       "3          7.418302       0.192747  0.174416                  0.268146   \n",
       "4          6.838088       0.163289  0.150331                  0.247174   \n",
       "5          5.099884       0.121510  0.109615                  0.184344   \n",
       "6          4.181281       0.084732  0.073801                  0.151139   \n",
       "7          3.554596       0.060526  0.054956                  0.128487   \n",
       "8          2.753585       0.041625  0.038938                  0.099533   \n",
       "9          2.221194       0.022555  0.026217                  0.080289   \n",
       "10         1.860990       0.015188  0.018301                  0.067268   \n",
       "11         1.599135       0.010478  0.012958                  0.057803   \n",
       "12         1.398787       0.007109  0.009110                  0.050561   \n",
       "13         1.237562       0.003940  0.006209                  0.044734   \n",
       "14         1.107163       0.002313  0.003883                  0.040020   \n",
       "15         1.000000       0.001285  0.001771                  0.036147   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.446474      0.105442                 0.105442  954.322761   \n",
       "1           0.357386      0.076376                 0.181818  663.692966   \n",
       "2           0.307937      0.061607                 0.243425  516.008804   \n",
       "3           0.274564      0.053313                 0.296738  433.236765   \n",
       "4           0.249716      0.045178                 0.341916  351.739790   \n",
       "5           0.179667      0.168075                 0.509991  236.158061   \n",
       "6           0.144378      0.117210                 0.627202  134.412631   \n",
       "7           0.122023      0.083722                 0.710923   67.447154   \n",
       "8           0.094328      0.115157                 0.826080   15.156123   \n",
       "9           0.077301      0.062396                 0.888476  -37.602240   \n",
       "10          0.065501      0.042019                 0.930495  -57.981442   \n",
       "11          0.056743      0.028987                 0.959482  -71.013514   \n",
       "12          0.049939      0.019667                 0.979149  -80.332858   \n",
       "13          0.044473      0.010900                 0.990048  -89.100449   \n",
       "14          0.039963      0.006398                 0.996446  -93.602438   \n",
       "15          0.036143      0.003554                 1.000000  -96.445799   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        954.322761            0.099020  \n",
       "1        809.007863            0.167885  \n",
       "2        711.341510            0.221426  \n",
       "3        641.830211            0.266365  \n",
       "4        583.808814            0.302862  \n",
       "5        409.988400            0.425366  \n",
       "6        318.128062            0.495095  \n",
       "7        255.459624            0.530083  \n",
       "8        175.358457            0.545807  \n",
       "9        122.119423            0.506796  \n",
       "10        86.099044            0.446640  \n",
       "11        59.913493            0.372963  \n",
       "12        39.878709            0.289619  \n",
       "13        23.756199            0.197177  \n",
       "14        10.716268            0.100063  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.031085188182299453\n",
      "RMSE: 0.17630992082778396\n",
      "LogLoss: 0.12278299434179599\n",
      "Null degrees of freedom: 74970\n",
      "Residual degrees of freedom: 74883\n",
      "Null deviance: 22974.59746448409\n",
      "Residual deviance: 18410.327737597574\n",
      "AIC: 18586.327737597574\n",
      "AUC: 0.8449582112507165\n",
      "AUCPR: 0.1975656889474204\n",
      "Gini: 0.6899164225014329\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.12239564072349282: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>68666.0</td>\n",
       "      <td>3647.0</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>(3647.0/72313.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>(1620.0/2658.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>70286.0</td>\n",
       "      <td>4685.0</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>(5267.0/74971.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FALSE    TRUE   Error               Rate\n",
       "0  FALSE  68666.0  3647.0  0.0504   (3647.0/72313.0)\n",
       "1   TRUE   1620.0  1038.0  0.6095    (1620.0/2658.0)\n",
       "2  Total  70286.0  4685.0  0.0703   (5267.0/74971.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.122396</td>\n",
       "      <td>0.282718</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.063173</td>\n",
       "      <td>0.373275</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.229540</td>\n",
       "      <td>0.288998</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.963906</td>\n",
       "      <td>0.964533</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.391435</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.963906</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.122396</td>\n",
       "      <td>0.259827</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.038297</td>\n",
       "      <td>0.765506</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.039845</td>\n",
       "      <td>0.767850</td>\n",
       "      <td>301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.963906</td>\n",
       "      <td>72312.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.963906</td>\n",
       "      <td>2658.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>72313.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>2658.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.963906</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.963906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.122396      0.282718  205.0\n",
       "1                        max f2   0.063173      0.373275  266.0\n",
       "2                  max f0point5   0.229540      0.288998  137.0\n",
       "3                  max accuracy   0.963906      0.964533    0.0\n",
       "4                 max precision   0.391435      0.393939   78.0\n",
       "5                    max recall   0.000519      1.000000  399.0\n",
       "6               max specificity   0.963906      0.999986    0.0\n",
       "7              max absolute_mcc   0.122396      0.259827  205.0\n",
       "8    max min_per_class_accuracy   0.038297      0.765506  304.0\n",
       "9   max mean_per_class_accuracy   0.039845      0.767850  301.0\n",
       "10                      max tns   0.963906  72312.000000    0.0\n",
       "11                      max fns   0.963906   2658.000000    0.0\n",
       "12                      max fps   0.000519  72313.000000  399.0\n",
       "13                      max tps   0.000519   2658.000000  399.0\n",
       "14                      max tnr   0.963906      0.999986    0.0\n",
       "15                      max fnr   0.963906      1.000000    0.0\n",
       "16                      max fpr   0.000519      1.000000  399.0\n",
       "17                      max tpr   0.000519      1.000000  399.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  3.55 %, avg score:  3.62 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>0.317181</td>\n",
       "      <td>10.304517</td>\n",
       "      <td>10.304517</td>\n",
       "      <td>0.365333</td>\n",
       "      <td>0.454563</td>\n",
       "      <td>0.365333</td>\n",
       "      <td>0.454563</td>\n",
       "      <td>0.103085</td>\n",
       "      <td>0.103085</td>\n",
       "      <td>930.451668</td>\n",
       "      <td>930.451668</td>\n",
       "      <td>0.096503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.233854</td>\n",
       "      <td>8.386523</td>\n",
       "      <td>9.345520</td>\n",
       "      <td>0.297333</td>\n",
       "      <td>0.270489</td>\n",
       "      <td>0.331333</td>\n",
       "      <td>0.362526</td>\n",
       "      <td>0.083898</td>\n",
       "      <td>0.186983</td>\n",
       "      <td>738.652270</td>\n",
       "      <td>834.551969</td>\n",
       "      <td>0.173112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030012</td>\n",
       "      <td>0.187984</td>\n",
       "      <td>6.318098</td>\n",
       "      <td>8.336379</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.208481</td>\n",
       "      <td>0.295556</td>\n",
       "      <td>0.311178</td>\n",
       "      <td>0.063205</td>\n",
       "      <td>0.250188</td>\n",
       "      <td>531.809782</td>\n",
       "      <td>733.637907</td>\n",
       "      <td>0.228270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.159089</td>\n",
       "      <td>4.631926</td>\n",
       "      <td>7.411192</td>\n",
       "      <td>0.164219</td>\n",
       "      <td>0.172381</td>\n",
       "      <td>0.262754</td>\n",
       "      <td>0.276513</td>\n",
       "      <td>0.046275</td>\n",
       "      <td>0.296464</td>\n",
       "      <td>363.192609</td>\n",
       "      <td>641.119224</td>\n",
       "      <td>0.265888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050006</td>\n",
       "      <td>0.139521</td>\n",
       "      <td>4.136850</td>\n",
       "      <td>6.756149</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.149179</td>\n",
       "      <td>0.239531</td>\n",
       "      <td>0.251039</td>\n",
       "      <td>0.041384</td>\n",
       "      <td>0.337848</td>\n",
       "      <td>313.684976</td>\n",
       "      <td>575.614907</td>\n",
       "      <td>0.298422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>0.087391</td>\n",
       "      <td>3.212556</td>\n",
       "      <td>4.984353</td>\n",
       "      <td>0.113897</td>\n",
       "      <td>0.109604</td>\n",
       "      <td>0.176714</td>\n",
       "      <td>0.180322</td>\n",
       "      <td>0.160647</td>\n",
       "      <td>0.498495</td>\n",
       "      <td>221.255641</td>\n",
       "      <td>398.435274</td>\n",
       "      <td>0.413130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150005</td>\n",
       "      <td>0.062516</td>\n",
       "      <td>2.325398</td>\n",
       "      <td>4.098192</td>\n",
       "      <td>0.082444</td>\n",
       "      <td>0.073868</td>\n",
       "      <td>0.145296</td>\n",
       "      <td>0.144843</td>\n",
       "      <td>0.116253</td>\n",
       "      <td>0.614748</td>\n",
       "      <td>132.539762</td>\n",
       "      <td>309.819199</td>\n",
       "      <td>0.481826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200011</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>1.737940</td>\n",
       "      <td>3.508090</td>\n",
       "      <td>0.061616</td>\n",
       "      <td>0.054946</td>\n",
       "      <td>0.124375</td>\n",
       "      <td>0.122367</td>\n",
       "      <td>0.086907</td>\n",
       "      <td>0.701655</td>\n",
       "      <td>73.794035</td>\n",
       "      <td>250.808973</td>\n",
       "      <td>0.520084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300009</td>\n",
       "      <td>0.031163</td>\n",
       "      <td>1.124921</td>\n",
       "      <td>2.713735</td>\n",
       "      <td>0.039883</td>\n",
       "      <td>0.038898</td>\n",
       "      <td>0.096212</td>\n",
       "      <td>0.094545</td>\n",
       "      <td>0.112491</td>\n",
       "      <td>0.814146</td>\n",
       "      <td>12.492095</td>\n",
       "      <td>171.373545</td>\n",
       "      <td>0.533035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400008</td>\n",
       "      <td>0.021594</td>\n",
       "      <td>0.665923</td>\n",
       "      <td>2.201799</td>\n",
       "      <td>0.023609</td>\n",
       "      <td>0.026044</td>\n",
       "      <td>0.078062</td>\n",
       "      <td>0.077421</td>\n",
       "      <td>0.066591</td>\n",
       "      <td>0.880737</td>\n",
       "      <td>-33.407690</td>\n",
       "      <td>120.179944</td>\n",
       "      <td>0.498400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500007</td>\n",
       "      <td>0.015229</td>\n",
       "      <td>0.462760</td>\n",
       "      <td>1.854001</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.018211</td>\n",
       "      <td>0.065731</td>\n",
       "      <td>0.065579</td>\n",
       "      <td>0.046275</td>\n",
       "      <td>0.927013</td>\n",
       "      <td>-53.723988</td>\n",
       "      <td>85.400085</td>\n",
       "      <td>0.442702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600005</td>\n",
       "      <td>0.010776</td>\n",
       "      <td>0.331080</td>\n",
       "      <td>1.600186</td>\n",
       "      <td>0.011738</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>0.056733</td>\n",
       "      <td>0.056795</td>\n",
       "      <td>0.033108</td>\n",
       "      <td>0.960120</td>\n",
       "      <td>-66.891959</td>\n",
       "      <td>60.018642</td>\n",
       "      <td>0.373352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700004</td>\n",
       "      <td>0.007520</td>\n",
       "      <td>0.158016</td>\n",
       "      <td>1.394166</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>0.049428</td>\n",
       "      <td>0.049977</td>\n",
       "      <td>0.015801</td>\n",
       "      <td>0.975922</td>\n",
       "      <td>-84.198435</td>\n",
       "      <td>39.416595</td>\n",
       "      <td>0.286060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.800003</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.146729</td>\n",
       "      <td>1.238239</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.044502</td>\n",
       "      <td>0.014673</td>\n",
       "      <td>0.990594</td>\n",
       "      <td>-85.327118</td>\n",
       "      <td>23.823891</td>\n",
       "      <td>0.197597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.900001</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.045147</td>\n",
       "      <td>1.105675</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>0.039984</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.995109</td>\n",
       "      <td>-95.485267</td>\n",
       "      <td>10.567514</td>\n",
       "      <td>0.098604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.048910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>0.036160</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-95.109039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold       lift  \\\n",
       "0       1                  0.010004         0.317181  10.304517   \n",
       "1       2                  0.020008         0.233854   8.386523   \n",
       "2       3                  0.030012         0.187984   6.318098   \n",
       "3       4                  0.040002         0.159089   4.631926   \n",
       "4       5                  0.050006         0.139521   4.136850   \n",
       "5       6                  0.100012         0.087391   3.212556   \n",
       "6       7                  0.150005         0.062516   2.325398   \n",
       "7       8                  0.200011         0.048240   1.737940   \n",
       "8       9                  0.300009         0.031163   1.124921   \n",
       "9      10                  0.400008         0.021594   0.665923   \n",
       "10     11                  0.500007         0.015229   0.462760   \n",
       "11     12                  0.600005         0.010776   0.331080   \n",
       "12     13                  0.700004         0.007520   0.158016   \n",
       "13     14                  0.800003         0.004929   0.146729   \n",
       "14     15                  0.900001         0.002822   0.045147   \n",
       "15     16                  1.000000         0.000123   0.048910   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0         10.304517       0.365333  0.454563                  0.365333   \n",
       "1          9.345520       0.297333  0.270489                  0.331333   \n",
       "2          8.336379       0.224000  0.208481                  0.295556   \n",
       "3          7.411192       0.164219  0.172381                  0.262754   \n",
       "4          6.756149       0.146667  0.149179                  0.239531   \n",
       "5          4.984353       0.113897  0.109604                  0.176714   \n",
       "6          4.098192       0.082444  0.073868                  0.145296   \n",
       "7          3.508090       0.061616  0.054946                  0.124375   \n",
       "8          2.713735       0.039883  0.038898                  0.096212   \n",
       "9          2.201799       0.023609  0.026044                  0.078062   \n",
       "10         1.854001       0.016407  0.018211                  0.065731   \n",
       "11         1.600186       0.011738  0.012876                  0.056733   \n",
       "12         1.394166       0.005602  0.009064                  0.049428   \n",
       "13         1.238239       0.005202  0.006181                  0.043900   \n",
       "14         1.105675       0.001601  0.003836                  0.039200   \n",
       "15         1.000000       0.001734  0.001748                  0.035454   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.454563      0.103085                 0.103085  930.451668   \n",
       "1           0.362526      0.083898                 0.186983  738.652270   \n",
       "2           0.311178      0.063205                 0.250188  531.809782   \n",
       "3           0.276513      0.046275                 0.296464  363.192609   \n",
       "4           0.251039      0.041384                 0.337848  313.684976   \n",
       "5           0.180322      0.160647                 0.498495  221.255641   \n",
       "6           0.144843      0.116253                 0.614748  132.539762   \n",
       "7           0.122367      0.086907                 0.701655   73.794035   \n",
       "8           0.094545      0.112491                 0.814146   12.492095   \n",
       "9           0.077421      0.066591                 0.880737  -33.407690   \n",
       "10          0.065579      0.046275                 0.927013  -53.723988   \n",
       "11          0.056795      0.033108                 0.960120  -66.891959   \n",
       "12          0.049977      0.015801                 0.975922  -84.198435   \n",
       "13          0.044502      0.014673                 0.990594  -85.327118   \n",
       "14          0.039984      0.004515                 0.995109  -95.485267   \n",
       "15          0.036160      0.004891                 1.000000  -95.109039   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0        930.451668            0.096503  \n",
       "1        834.551969            0.173112  \n",
       "2        733.637907            0.228270  \n",
       "3        641.119224            0.265888  \n",
       "4        575.614907            0.298422  \n",
       "5        398.435274            0.413130  \n",
       "6        309.819199            0.481826  \n",
       "7        250.808973            0.520084  \n",
       "8        171.373545            0.533035  \n",
       "9        120.179944            0.498400  \n",
       "10        85.400085            0.442702  \n",
       "11        60.018642            0.373352  \n",
       "12        39.416595            0.286060  \n",
       "13        23.823891            0.197597  \n",
       "14        10.567514            0.098604  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>iterations</th>\n",
       "      <th>negative_log_likelihood</th>\n",
       "      <th>objective</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_r2</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_r2</th>\n",
       "      <th>validation_auc</th>\n",
       "      <th>validation_pr_auc</th>\n",
       "      <th>validation_lift</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:18:49</td>\n",
       "      <td>0.000 sec</td>\n",
       "      <td>0</td>\n",
       "      <td>54466.065752</td>\n",
       "      <td>0.155498</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:18:49</td>\n",
       "      <td>0.296 sec</td>\n",
       "      <td>1</td>\n",
       "      <td>50061.613368</td>\n",
       "      <td>0.144447</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:18:50</td>\n",
       "      <td>0.335 sec</td>\n",
       "      <td>2</td>\n",
       "      <td>43570.207802</td>\n",
       "      <td>0.125483</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:18:50</td>\n",
       "      <td>0.376 sec</td>\n",
       "      <td>3</td>\n",
       "      <td>43215.311321</td>\n",
       "      <td>0.124491</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:18:50</td>\n",
       "      <td>0.415 sec</td>\n",
       "      <td>4</td>\n",
       "      <td>43195.943426</td>\n",
       "      <td>0.124463</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:18:50</td>\n",
       "      <td>0.452 sec</td>\n",
       "      <td>5</td>\n",
       "      <td>43195.779638</td>\n",
       "      <td>0.124463</td>\n",
       "      <td>0.177284</td>\n",
       "      <td>0.123322</td>\n",
       "      <td>0.0978884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.5432</td>\n",
       "      <td>0.0673056</td>\n",
       "      <td>0.17631</td>\n",
       "      <td>0.122783</td>\n",
       "      <td>0.0909898</td>\n",
       "      <td>0.844958</td>\n",
       "      <td>0.197566</td>\n",
       "      <td>10.3045</td>\n",
       "      <td>0.0702538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration  iterations  negative_log_likelihood  \\\n",
       "0    2020-09-22 07:18:49   0.000 sec           0             54466.065752   \n",
       "1    2020-09-22 07:18:49   0.296 sec           1             50061.613368   \n",
       "2    2020-09-22 07:18:50   0.335 sec           2             43570.207802   \n",
       "3    2020-09-22 07:18:50   0.376 sec           3             43215.311321   \n",
       "4    2020-09-22 07:18:50   0.415 sec           4             43195.943426   \n",
       "5    2020-09-22 07:18:50   0.452 sec           5             43195.779638   \n",
       "\n",
       "   objective training_rmse training_logloss training_r2 training_auc  \\\n",
       "0   0.155498                                                           \n",
       "1   0.144447                                                           \n",
       "2   0.125483                                                           \n",
       "3   0.124491                                                           \n",
       "4   0.124463                                                           \n",
       "5   0.124463      0.177284         0.123322   0.0978884          NaN   \n",
       "\n",
       "  training_pr_auc training_lift training_classification_error validation_rmse  \\\n",
       "0                                                                               \n",
       "1                                                                               \n",
       "2                                                                               \n",
       "3                                                                               \n",
       "4                                                                               \n",
       "5             NaN       10.5432                     0.0673056         0.17631   \n",
       "\n",
       "  validation_logloss validation_r2 validation_auc validation_pr_auc  \\\n",
       "0                                                                     \n",
       "1                                                                     \n",
       "2                                                                     \n",
       "3                                                                     \n",
       "4                                                                     \n",
       "5           0.122783     0.0909898       0.844958          0.197566   \n",
       "\n",
       "  validation_lift validation_classification_error  \n",
       "0                                                  \n",
       "1                                                  \n",
       "2                                                  \n",
       "3                                                  \n",
       "4                                                  \n",
       "5         10.3045                       0.0702538  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From the summary results, we can see the GLM performance. We will focus on the Area Under the Curve (AUC), and since we have a very imbalanced dataset, we will be looking at the F1 score. Additionally, we will also take a quick look at the misclassification error and logloss.\n",
    "\n",
    "From the report, we can look at the metrics on the training and validation data, and we see that the training AUC was 0.8502 while the validation AUC was 0.8450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can plot the Scoring history for any of our models, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.plot(metric='negative_log_likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can see from the plot above that after four iterations, the score no longer improves; therefore, if we needed to set a number of iterations as a future parameter, we can choose 4, as the scores don’t really improve after that point. We can also use the default number of iterations and use early stopping; that way, the model will stop training when it is no longer improving. We will use early stopping when we start tuning our models.\n",
    "\n",
    "We can also generate a variable importance plot to see how each of our features contribute to the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.varimp_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From the variable importance plot, we can see that the most significant feature is SERVICER_NAME. In the most important feature, we have different banks or “servicers,” and in our linear model, each one makes a difference; for that reason, we see that the first four variables in the plot above are 4 of the servicers in the dataset. These services are the most influential to our model in making predictions of whether someone will default or not. Please keep in mind that it does not necessarily mean that if someone gets a loan from Wells Fargo, they have a high probability of default.\n",
    "\n",
    "We will take a look at the first ten predictions of our model with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">   FALSE</th><th style=\"text-align: right;\">      TRUE</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.994214</td><td style=\"text-align: right;\">0.00578569</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.997228</td><td style=\"text-align: right;\">0.00277241</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.964336</td><td style=\"text-align: right;\">0.0356639 </td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.996117</td><td style=\"text-align: right;\">0.00388337</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.996172</td><td style=\"text-align: right;\">0.00382811</td></tr>\n",
       "<tr><td>TRUE     </td><td style=\"text-align: right;\">0.652586</td><td style=\"text-align: right;\">0.347414  </td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.994137</td><td style=\"text-align: right;\">0.00586319</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.995791</td><td style=\"text-align: right;\">0.00420864</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.958106</td><td style=\"text-align: right;\">0.0418938 </td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.994599</td><td style=\"text-align: right;\">0.00540108</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm.predict(valid).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note: if you want to see more predictions use the .head() function, as shown in the line of code above; it should allow you to view all the predictions on the validation set that you want.\n",
    "\n",
    "The model used by H2O for this classification problem is a Logistic Regression model, and the predictions are based on the threshold for each probability[1]. For a binary classifier, H2O predicts the labels based on the maximum F1 threshold. From the report, the threshold for max F1 is 0.1224. So, any time the probability for TRUE is greater than the 0.1224, the predicted label will be TRUE, as is in the case of the sixth prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "default_glm_perf=glm.model_performance(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once you save the model performance on a different data set, you can print individual metrics, such as the AUC as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8449582112507165\n"
     ]
    }
   ],
   "source": [
    "print(default_glm_perf.auc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Want to learn more?\n",
    "[H2O-3 GLM Logistic Regression](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html#logistic-regression-binomial-family)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Tune the GLM with H2O GridSearch\n",
    "\n",
    "Hyperparameter Tuning is nothing but searching for the right set of hyperparameter to achieve high precision and accuracy. Optimising hyperparameters constitute one of the most trickiest part in building the machine learning models. The primary aim of hyperparameter tuning is to find the sweet spot for the model’s parameters so that a better performance is obtained.\n",
    "\n",
    "Two of the most widely-used parameter optimising techniques:-\n",
    "* Grid Search\n",
    "* Random Search\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cartesian Grid Search\n",
    "\n",
    "![](https://miro.medium.com/max/363/0*4O9P0rwkJGmFr8r6)\n",
    "\n",
    "\n",
    "source: https://analyticsindiamag.com/why-is-random-search-better-than-grid-search-for-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Search\n",
    "![](https://analyticsindiamag.com/wp-content/uploads/2018/06/random.png)\n",
    "\n",
    "source: https://analyticsindiamag.com/why-is-random-search-better-than-grid-search-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Grid Build progress: |████████████████████████████████████████████████| 100%\n",
      "CPU times: user 3.42 s, sys: 312 ms, total: 3.73 s\n",
      "Wall time: 5min 4s\n"
     ]
    }
   ],
   "source": [
    "glm_grid = h2o.grid.H2OGridSearch (\n",
    "    H2OGeneralizedLinearEstimator( \n",
    "        family = \"binomial\",\n",
    "        lambda_search = True),\n",
    "    \n",
    "    hyper_params = {\n",
    "        \"alpha\": [x*0.01 for x in range(0, 100)],\n",
    "        \"missing_values_handling\" : [\"Skip\", \"MeanImputation\"],\n",
    "        },\n",
    "    \n",
    "    grid_id = \"glm_random_grid\",\n",
    "    \n",
    "    search_criteria = {\n",
    "        \"strategy\":\"RandomDiscrete\",\n",
    "        \"max_models\":300,\n",
    "        \"max_runtime_secs\":300,\n",
    "        \"seed\":42\n",
    "        }\n",
    ")\n",
    "\n",
    "%time glm_grid.train(x=x, y=y, training_frame=train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>missing_values_handling</th>\n",
       "      <th>model_ids</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>[0.37]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_23</td>\n",
       "      <td>0.8534303606229077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>[0.34]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_13</td>\n",
       "      <td>0.8534213105313417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>[0.51]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_11</td>\n",
       "      <td>0.853412967251469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>[0.44]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_3</td>\n",
       "      <td>0.8534125661838832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>[0.32]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_6</td>\n",
       "      <td>0.8534101150897196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>[0.54]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_21</td>\n",
       "      <td>0.8534092610004044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>[0.33]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_2</td>\n",
       "      <td>0.8533966056268216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>[0.23]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_32</td>\n",
       "      <td>0.8533940204321417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>[0.12]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_1</td>\n",
       "      <td>0.8533594561376638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>[0.87]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_16</td>\n",
       "      <td>0.8533582915920229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>[0.17]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_12</td>\n",
       "      <td>0.8533505891615186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_31</td>\n",
       "      <td>0.8533442638907971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>[0.96]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_25</td>\n",
       "      <td>0.8533298689469624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>[0.11]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_8</td>\n",
       "      <td>0.8533106660242369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>[0.7000000000000001]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_24</td>\n",
       "      <td>0.8533038913645336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>[0.13]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_22</td>\n",
       "      <td>0.8533005281953798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>[0.77]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_27</td>\n",
       "      <td>0.8533005136989611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>[0.2]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_18</td>\n",
       "      <td>0.8532963000732398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>[0.84]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_30</td>\n",
       "      <td>0.8532641615128354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>[0.09]</td>\n",
       "      <td>Skip</td>\n",
       "      <td>glm_random_grid_model_26</td>\n",
       "      <td>0.8532073742083893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>[0.17]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_19</td>\n",
       "      <td>0.8461221485142078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>[0.72]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_20</td>\n",
       "      <td>0.8461075445400141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>[0.37]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_17</td>\n",
       "      <td>0.8460556138067002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>[0.96]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_15</td>\n",
       "      <td>0.8460535041125301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>[0.27]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_9</td>\n",
       "      <td>0.8460435383438919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_14</td>\n",
       "      <td>0.846043267803579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>[0.93]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_4</td>\n",
       "      <td>0.8460430753037411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>[0.48]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_10</td>\n",
       "      <td>0.8460412127377414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>[0.68]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_28</td>\n",
       "      <td>0.8460391654759511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>[0.98]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_29</td>\n",
       "      <td>0.8460358695665633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>[0.81]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_33</td>\n",
       "      <td>0.8460305289967345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>[0.11]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_7</td>\n",
       "      <td>0.8460139323890831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td>[0.92]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_5</td>\n",
       "      <td>0.8460063546589752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>[0.01]</td>\n",
       "      <td>MeanImputation</td>\n",
       "      <td>glm_random_grid_model_34</td>\n",
       "      <td>0.7994622818783035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     alpha missing_values_handling                 model_ids  \\\n",
       "0                   [0.37]                    Skip  glm_random_grid_model_23   \n",
       "1                   [0.34]                    Skip  glm_random_grid_model_13   \n",
       "2                   [0.51]                    Skip  glm_random_grid_model_11   \n",
       "3                   [0.44]                    Skip   glm_random_grid_model_3   \n",
       "4                   [0.32]                    Skip   glm_random_grid_model_6   \n",
       "5                   [0.54]                    Skip  glm_random_grid_model_21   \n",
       "6                   [0.33]                    Skip   glm_random_grid_model_2   \n",
       "7                   [0.23]                    Skip  glm_random_grid_model_32   \n",
       "8                   [0.12]                    Skip   glm_random_grid_model_1   \n",
       "9                   [0.87]                    Skip  glm_random_grid_model_16   \n",
       "10                  [0.17]                    Skip  glm_random_grid_model_12   \n",
       "11                   [0.5]                    Skip  glm_random_grid_model_31   \n",
       "12                  [0.96]                    Skip  glm_random_grid_model_25   \n",
       "13                  [0.11]                    Skip   glm_random_grid_model_8   \n",
       "14    [0.7000000000000001]                    Skip  glm_random_grid_model_24   \n",
       "15                  [0.13]                    Skip  glm_random_grid_model_22   \n",
       "16                  [0.77]                    Skip  glm_random_grid_model_27   \n",
       "17                   [0.2]                    Skip  glm_random_grid_model_18   \n",
       "18                  [0.84]                    Skip  glm_random_grid_model_30   \n",
       "19                  [0.09]                    Skip  glm_random_grid_model_26   \n",
       "20                  [0.17]          MeanImputation  glm_random_grid_model_19   \n",
       "21                  [0.72]          MeanImputation  glm_random_grid_model_20   \n",
       "22                  [0.37]          MeanImputation  glm_random_grid_model_17   \n",
       "23                  [0.96]          MeanImputation  glm_random_grid_model_15   \n",
       "24                  [0.27]          MeanImputation   glm_random_grid_model_9   \n",
       "25                   [0.5]          MeanImputation  glm_random_grid_model_14   \n",
       "26                  [0.93]          MeanImputation   glm_random_grid_model_4   \n",
       "27                  [0.48]          MeanImputation  glm_random_grid_model_10   \n",
       "28                  [0.68]          MeanImputation  glm_random_grid_model_28   \n",
       "29                  [0.98]          MeanImputation  glm_random_grid_model_29   \n",
       "30                  [0.81]          MeanImputation  glm_random_grid_model_33   \n",
       "31                  [0.11]          MeanImputation   glm_random_grid_model_7   \n",
       "32                  [0.92]          MeanImputation   glm_random_grid_model_5   \n",
       "33                  [0.01]          MeanImputation  glm_random_grid_model_34   \n",
       "\n",
       "                   auc  \n",
       "0   0.8534303606229077  \n",
       "1   0.8534213105313417  \n",
       "2    0.853412967251469  \n",
       "3   0.8534125661838832  \n",
       "4   0.8534101150897196  \n",
       "5   0.8534092610004044  \n",
       "6   0.8533966056268216  \n",
       "7   0.8533940204321417  \n",
       "8   0.8533594561376638  \n",
       "9   0.8533582915920229  \n",
       "10  0.8533505891615186  \n",
       "11  0.8533442638907971  \n",
       "12  0.8533298689469624  \n",
       "13  0.8533106660242369  \n",
       "14  0.8533038913645336  \n",
       "15  0.8533005281953798  \n",
       "16  0.8533005136989611  \n",
       "17  0.8532963000732398  \n",
       "18  0.8532641615128354  \n",
       "19  0.8532073742083893  \n",
       "20  0.8461221485142078  \n",
       "21  0.8461075445400141  \n",
       "22  0.8460556138067002  \n",
       "23  0.8460535041125301  \n",
       "24  0.8460435383438919  \n",
       "25   0.846043267803579  \n",
       "26  0.8460430753037411  \n",
       "27  0.8460412127377414  \n",
       "28  0.8460391654759511  \n",
       "29  0.8460358695665633  \n",
       "30  0.8460305289967345  \n",
       "31  0.8460139323890831  \n",
       "32  0.8460063546589752  \n",
       "33  0.7994622818783035  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_glm_grid = glm_grid.get_grid(sort_by='auc',decreasing=True)\n",
    "sorted_glm_grid.sorted_metric_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GLM Model: summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>link</th>\n",
       "      <th>regularization</th>\n",
       "      <th>lambda_search</th>\n",
       "      <th>number_of_predictors_total</th>\n",
       "      <th>number_of_active_predictors</th>\n",
       "      <th>number_of_iterations</th>\n",
       "      <th>training_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>binomial</td>\n",
       "      <td>logit</td>\n",
       "      <td>Elastic Net (alpha = 0.37, lambda = 1.187E-5 )</td>\n",
       "      <td>nlambda = 100, lambda.max = 0.08978, lambda.min = 1.187E-5, lambda...</td>\n",
       "      <td>161</td>\n",
       "      <td>146</td>\n",
       "      <td>143</td>\n",
       "      <td>py_4_sid_b63e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       family   link                                  regularization  \\\n",
       "0    binomial  logit  Elastic Net (alpha = 0.37, lambda = 1.187E-5 )   \n",
       "\n",
       "                                                           lambda_search  \\\n",
       "0  nlambda = 100, lambda.max = 0.08978, lambda.min = 1.187E-5, lambda...   \n",
       "\n",
       "   number_of_predictors_total number_of_active_predictors  \\\n",
       "0                         161                         146   \n",
       "\n",
       "   number_of_iterations training_frame  \n",
       "0                   143  py_4_sid_b63e  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_glm = sorted_glm_grid.models[0]\n",
    "tuned_glm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, evaluate the model performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tuned_glm_perf = tuned_glm.model_performance(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, print the AUC for the default, and the tuned model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GLM AUC: 0.8450 \n",
      "Tuned GLM AUC:0.8534\n"
     ]
    }
   ],
   "source": [
    "print(\"Default GLM AUC: %.4f \\nTuned GLM AUC:%.4f\" % (default_glm_perf.auc(), tuned_glm_perf.auc()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Build a GBM\n",
    "\n",
    "Gradient Boosting Machine (for Regression and Classification) is a forward learning ensemble method. H2O’s GBM sequentially builds classification trees on all the features of the dataset in a fully distributed way - each tree is built in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Defining a GBM model is as simple as the other models we have been working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parulpandey/anaconda3/lib/python3.7/site-packages/h2o/estimators/estimator_base.py:200: RuntimeWarning: Dropping bad and constant columns: [LOAN_SEQUENCE_NUMBER]\n",
      "  warnings.warn(mesg[\"message\"], RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "CPU times: user 202 ms, sys: 40.5 ms, total: 242 ms\n",
      "Wall time: 8.39 s\n"
     ]
    }
   ],
   "source": [
    "gbm= H2OGradientBoostingEstimator(seed=42, model_id='default_gbm')\n",
    "%time gbm.train(x=x, y=y, training_frame=train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Print the model summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  default_gbm\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>28333.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               50.0                      50.0              28333.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        5.0        5.0         5.0        25.0        32.0        30.96  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.029506421363469603\n",
      "RMSE: 0.1717743326678046\n",
      "LogLoss: 0.11505127038888412\n",
      "Mean Per-Class Error: 0.2023858106060208\n",
      "AUC: 0.8781930114270322\n",
      "AUCPR: 0.2950390694946684\n",
      "Gini: 0.7563860228540644\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.15607572690204796: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>326792.0</td>\n",
       "      <td>10815.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>(10815.0/337607.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>7794.0</td>\n",
       "      <td>4867.0</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>(7794.0/12661.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>334586.0</td>\n",
       "      <td>15682.0</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>(18609.0/350268.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FALSE     TRUE   Error                 Rate\n",
       "0  FALSE  326792.0  10815.0   0.032   (10815.0/337607.0)\n",
       "1   TRUE    7794.0   4867.0  0.6156     (7794.0/12661.0)\n",
       "2  Total  334586.0  15682.0  0.0531   (18609.0/350268.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.156076</td>\n",
       "      <td>0.343436</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.075853</td>\n",
       "      <td>0.428220</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.365425</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.450803</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.896728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.896728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.144866</td>\n",
       "      <td>0.318378</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.039435</td>\n",
       "      <td>0.796595</td>\n",
       "      <td>308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.036126</td>\n",
       "      <td>0.797614</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.896728</td>\n",
       "      <td>337607.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.896728</td>\n",
       "      <td>12659.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>337607.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>12661.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.896728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.896728</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold          value    idx\n",
       "0                        max f1   0.156076       0.343436  192.0\n",
       "1                        max f2   0.075853       0.428220  261.0\n",
       "2                  max f0point5   0.269948       0.365425  131.0\n",
       "3                  max accuracy   0.450803       0.965035   72.0\n",
       "4                 max precision   0.896728       1.000000    0.0\n",
       "5                    max recall   0.003016       1.000000  399.0\n",
       "6               max specificity   0.896728       1.000000    0.0\n",
       "7              max absolute_mcc   0.144866       0.318378  200.0\n",
       "8    max min_per_class_accuracy   0.039435       0.796595  308.0\n",
       "9   max mean_per_class_accuracy   0.036126       0.797614  313.0\n",
       "10                      max tns   0.896728  337607.000000    0.0\n",
       "11                      max fns   0.896728   12659.000000    0.0\n",
       "12                      max fps   0.003016  337607.000000  399.0\n",
       "13                      max tps   0.003016   12661.000000  399.0\n",
       "14                      max tnr   0.896728       1.000000    0.0\n",
       "15                      max fnr   0.896728       0.999842    0.0\n",
       "16                      max fpr   0.003016       1.000000  399.0\n",
       "17                      max tpr   0.003016       1.000000  399.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  3.61 %, avg score:  3.62 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.345972</td>\n",
       "      <td>14.286666</td>\n",
       "      <td>14.286666</td>\n",
       "      <td>0.516415</td>\n",
       "      <td>0.479898</td>\n",
       "      <td>0.516415</td>\n",
       "      <td>0.479898</td>\n",
       "      <td>0.142880</td>\n",
       "      <td>0.142880</td>\n",
       "      <td>1328.666572</td>\n",
       "      <td>1328.666572</td>\n",
       "      <td>0.137862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.247640</td>\n",
       "      <td>9.011103</td>\n",
       "      <td>11.648884</td>\n",
       "      <td>0.325721</td>\n",
       "      <td>0.290490</td>\n",
       "      <td>0.421068</td>\n",
       "      <td>0.385194</td>\n",
       "      <td>0.090119</td>\n",
       "      <td>0.232999</td>\n",
       "      <td>801.110315</td>\n",
       "      <td>1064.888444</td>\n",
       "      <td>0.220985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030003</td>\n",
       "      <td>0.197997</td>\n",
       "      <td>7.139384</td>\n",
       "      <td>10.145718</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.220582</td>\n",
       "      <td>0.366733</td>\n",
       "      <td>0.330323</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.304399</td>\n",
       "      <td>613.938409</td>\n",
       "      <td>914.571765</td>\n",
       "      <td>0.284687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.166786</td>\n",
       "      <td>5.482464</td>\n",
       "      <td>8.980154</td>\n",
       "      <td>0.198172</td>\n",
       "      <td>0.181255</td>\n",
       "      <td>0.324602</td>\n",
       "      <td>0.293064</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.359213</td>\n",
       "      <td>448.246392</td>\n",
       "      <td>798.015384</td>\n",
       "      <td>0.331184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.144748</td>\n",
       "      <td>4.880685</td>\n",
       "      <td>8.160213</td>\n",
       "      <td>0.176420</td>\n",
       "      <td>0.155075</td>\n",
       "      <td>0.294964</td>\n",
       "      <td>0.265465</td>\n",
       "      <td>0.048811</td>\n",
       "      <td>0.408025</td>\n",
       "      <td>388.068514</td>\n",
       "      <td>716.021329</td>\n",
       "      <td>0.371450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>0.085874</td>\n",
       "      <td>3.405812</td>\n",
       "      <td>5.783080</td>\n",
       "      <td>0.123109</td>\n",
       "      <td>0.110567</td>\n",
       "      <td>0.209039</td>\n",
       "      <td>0.188018</td>\n",
       "      <td>0.170287</td>\n",
       "      <td>0.578311</td>\n",
       "      <td>240.581193</td>\n",
       "      <td>478.308048</td>\n",
       "      <td>0.496248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150002</td>\n",
       "      <td>0.059880</td>\n",
       "      <td>2.250930</td>\n",
       "      <td>4.605675</td>\n",
       "      <td>0.081363</td>\n",
       "      <td>0.071572</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.149202</td>\n",
       "      <td>0.112550</td>\n",
       "      <td>0.690862</td>\n",
       "      <td>125.092991</td>\n",
       "      <td>360.567455</td>\n",
       "      <td>0.561143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.044609</td>\n",
       "      <td>1.525981</td>\n",
       "      <td>3.835773</td>\n",
       "      <td>0.055159</td>\n",
       "      <td>0.051662</td>\n",
       "      <td>0.138650</td>\n",
       "      <td>0.124817</td>\n",
       "      <td>0.076297</td>\n",
       "      <td>0.767159</td>\n",
       "      <td>52.598067</td>\n",
       "      <td>283.577306</td>\n",
       "      <td>0.588428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300002</td>\n",
       "      <td>0.027793</td>\n",
       "      <td>0.992017</td>\n",
       "      <td>2.887854</td>\n",
       "      <td>0.035858</td>\n",
       "      <td>0.035153</td>\n",
       "      <td>0.104386</td>\n",
       "      <td>0.094929</td>\n",
       "      <td>0.099202</td>\n",
       "      <td>0.866361</td>\n",
       "      <td>-0.798292</td>\n",
       "      <td>188.785440</td>\n",
       "      <td>0.587599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.399999</td>\n",
       "      <td>0.019080</td>\n",
       "      <td>0.537884</td>\n",
       "      <td>2.300375</td>\n",
       "      <td>0.019443</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>0.083151</td>\n",
       "      <td>0.076950</td>\n",
       "      <td>0.053787</td>\n",
       "      <td>0.920148</td>\n",
       "      <td>-46.211551</td>\n",
       "      <td>130.037450</td>\n",
       "      <td>0.539656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.013850</td>\n",
       "      <td>0.326987</td>\n",
       "      <td>1.905695</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>0.016267</td>\n",
       "      <td>0.068884</td>\n",
       "      <td>0.064814</td>\n",
       "      <td>0.032699</td>\n",
       "      <td>0.952847</td>\n",
       "      <td>-67.301348</td>\n",
       "      <td>90.569465</td>\n",
       "      <td>0.469830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600001</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>0.203774</td>\n",
       "      <td>1.622040</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.012055</td>\n",
       "      <td>0.058631</td>\n",
       "      <td>0.056021</td>\n",
       "      <td>0.020378</td>\n",
       "      <td>0.973225</td>\n",
       "      <td>-79.622579</td>\n",
       "      <td>62.203990</td>\n",
       "      <td>0.387221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699998</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.134274</td>\n",
       "      <td>1.409506</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>0.986652</td>\n",
       "      <td>-86.572634</td>\n",
       "      <td>40.950620</td>\n",
       "      <td>0.297404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>0.073453</td>\n",
       "      <td>1.242498</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.044912</td>\n",
       "      <td>0.044077</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.993997</td>\n",
       "      <td>-92.654651</td>\n",
       "      <td>24.249842</td>\n",
       "      <td>0.201274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899999</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.044230</td>\n",
       "      <td>1.109357</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.005606</td>\n",
       "      <td>0.040099</td>\n",
       "      <td>0.039802</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.998420</td>\n",
       "      <td>-95.576994</td>\n",
       "      <td>10.935664</td>\n",
       "      <td>0.102112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>0.015796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.036147</td>\n",
       "      <td>0.036227</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-98.420355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold       lift  \\\n",
       "0       1                  0.010001         0.345972  14.286666   \n",
       "1       2                  0.020002         0.247640   9.011103   \n",
       "2       3                  0.030003         0.197997   7.139384   \n",
       "3       4                  0.040001         0.166786   5.482464   \n",
       "4       5                  0.050002         0.144748   4.880685   \n",
       "5       6                  0.100001         0.085874   3.405812   \n",
       "6       7                  0.150002         0.059880   2.250930   \n",
       "7       8                  0.200001         0.044609   1.525981   \n",
       "8       9                  0.300002         0.027793   0.992017   \n",
       "9      10                  0.399999         0.019080   0.537884   \n",
       "10     11                  0.500000         0.013850   0.326987   \n",
       "11     12                  0.600001         0.010488   0.203774   \n",
       "12     13                  0.699998         0.008156   0.134274   \n",
       "13     14                  0.799999         0.006371   0.073453   \n",
       "14     15                  0.899999         0.004872   0.044230   \n",
       "15     16                  1.000000         0.002477   0.015796   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0         14.286666       0.516415  0.479898                  0.516415   \n",
       "1         11.648884       0.325721  0.290490                  0.421068   \n",
       "2         10.145718       0.258065  0.220582                  0.366733   \n",
       "3          8.980154       0.198172  0.181255                  0.324602   \n",
       "4          8.160213       0.176420  0.155075                  0.294964   \n",
       "5          5.783080       0.123109  0.110567                  0.209039   \n",
       "6          4.605675       0.081363  0.071572                  0.166480   \n",
       "7          3.835773       0.055159  0.051662                  0.138650   \n",
       "8          2.887854       0.035858  0.035153                  0.104386   \n",
       "9          2.300375       0.019443  0.023012                  0.083151   \n",
       "10         1.905695       0.011819  0.016267                  0.068884   \n",
       "11         1.622040       0.007366  0.012055                  0.058631   \n",
       "12         1.409506       0.004854  0.009260                  0.050949   \n",
       "13         1.242498       0.002655  0.007231                  0.044912   \n",
       "14         1.109357       0.001599  0.005606                  0.040099   \n",
       "15         1.000000       0.000571  0.004052                  0.036147   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate         gain  \\\n",
       "0           0.479898      0.142880                 0.142880  1328.666572   \n",
       "1           0.385194      0.090119                 0.232999   801.110315   \n",
       "2           0.330323      0.071400                 0.304399   613.938409   \n",
       "3           0.293064      0.054814                 0.359213   448.246392   \n",
       "4           0.265465      0.048811                 0.408025   388.068514   \n",
       "5           0.188018      0.170287                 0.578311   240.581193   \n",
       "6           0.149202      0.112550                 0.690862   125.092991   \n",
       "7           0.124817      0.076297                 0.767159    52.598067   \n",
       "8           0.094929      0.099202                 0.866361    -0.798292   \n",
       "9           0.076950      0.053787                 0.920148   -46.211551   \n",
       "10          0.064814      0.032699                 0.952847   -67.301348   \n",
       "11          0.056021      0.020378                 0.973225   -79.622579   \n",
       "12          0.049341      0.013427                 0.986652   -86.572634   \n",
       "13          0.044077      0.007345                 0.993997   -92.654651   \n",
       "14          0.039802      0.004423                 0.998420   -95.576994   \n",
       "15          0.036227      0.001580                 1.000000   -98.420355   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0       1328.666572            0.137862  \n",
       "1       1064.888444            0.220985  \n",
       "2        914.571765            0.284687  \n",
       "3        798.015384            0.331184  \n",
       "4        716.021329            0.371450  \n",
       "5        478.308048            0.496248  \n",
       "6        360.567455            0.561143  \n",
       "7        283.577306            0.588428  \n",
       "8        188.785440            0.587599  \n",
       "9        130.037450            0.539656  \n",
       "10        90.569465            0.469830  \n",
       "11        62.203990            0.387221  \n",
       "12        40.950620            0.297404  \n",
       "13        24.249842            0.201274  \n",
       "14        10.935664            0.102112  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.030145356735784883\n",
      "RMSE: 0.17362418246253855\n",
      "LogLoss: 0.11952062413571642\n",
      "Mean Per-Class Error: 0.2242541716041575\n",
      "AUC: 0.8541170986087288\n",
      "AUCPR: 0.23773133290345963\n",
      "Gini: 0.7082341972174575\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1670709331729805: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>70224.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>(2089.0/72313.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>(1821.0/2658.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>72045.0</td>\n",
       "      <td>2926.0</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>(3910.0/74971.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FALSE    TRUE   Error               Rate\n",
       "0  FALSE  70224.0  2089.0  0.0289   (2089.0/72313.0)\n",
       "1   TRUE   1821.0   837.0  0.6851    (1821.0/2658.0)\n",
       "2  Total  72045.0  2926.0  0.0522   (3910.0/74971.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.167071</td>\n",
       "      <td>0.299785</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.392875</td>\n",
       "      <td>264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.251696</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.592678</td>\n",
       "      <td>0.964946</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.100167</td>\n",
       "      <td>0.279877</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.035648</td>\n",
       "      <td>0.773416</td>\n",
       "      <td>314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.031420</td>\n",
       "      <td>0.775746</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>72313.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>2657.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>72313.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>2658.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.167071      0.299785  178.0\n",
       "1                        max f2   0.070072      0.392875  264.0\n",
       "2                  max f0point5   0.251696      0.321232  132.0\n",
       "3                  max accuracy   0.592678      0.964946   29.0\n",
       "4                 max precision   0.895425      1.000000    0.0\n",
       "5                    max recall   0.003295      1.000000  398.0\n",
       "6               max specificity   0.895425      1.000000    0.0\n",
       "7              max absolute_mcc   0.100167      0.279877  230.0\n",
       "8    max min_per_class_accuracy   0.035648      0.773416  314.0\n",
       "9   max mean_per_class_accuracy   0.031420      0.775746  322.0\n",
       "10                      max tns   0.895425  72313.000000    0.0\n",
       "11                      max fns   0.895425   2657.000000    0.0\n",
       "12                      max fps   0.002972  72313.000000  399.0\n",
       "13                      max tps   0.003295   2658.000000  398.0\n",
       "14                      max tnr   0.895425      1.000000    0.0\n",
       "15                      max fnr   0.895425      0.999624    0.0\n",
       "16                      max fpr   0.002972      1.000000  399.0\n",
       "17                      max tpr   0.003295      1.000000  398.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  3.55 %, avg score:  3.60 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>0.344236</td>\n",
       "      <td>13.012273</td>\n",
       "      <td>13.012273</td>\n",
       "      <td>0.461333</td>\n",
       "      <td>0.473428</td>\n",
       "      <td>0.461333</td>\n",
       "      <td>0.473428</td>\n",
       "      <td>0.130173</td>\n",
       "      <td>0.130173</td>\n",
       "      <td>1201.227289</td>\n",
       "      <td>1201.227289</td>\n",
       "      <td>0.124586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.243068</td>\n",
       "      <td>7.784799</td>\n",
       "      <td>10.398536</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.287629</td>\n",
       "      <td>0.368667</td>\n",
       "      <td>0.380528</td>\n",
       "      <td>0.077878</td>\n",
       "      <td>0.208051</td>\n",
       "      <td>678.479910</td>\n",
       "      <td>939.853599</td>\n",
       "      <td>0.194955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030012</td>\n",
       "      <td>0.195026</td>\n",
       "      <td>6.054844</td>\n",
       "      <td>8.950639</td>\n",
       "      <td>0.214667</td>\n",
       "      <td>0.217315</td>\n",
       "      <td>0.317333</td>\n",
       "      <td>0.326124</td>\n",
       "      <td>0.060572</td>\n",
       "      <td>0.268623</td>\n",
       "      <td>505.484374</td>\n",
       "      <td>795.063858</td>\n",
       "      <td>0.247382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.163482</td>\n",
       "      <td>4.933190</td>\n",
       "      <td>7.947281</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.178416</td>\n",
       "      <td>0.281761</td>\n",
       "      <td>0.289234</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.317908</td>\n",
       "      <td>393.318958</td>\n",
       "      <td>694.728102</td>\n",
       "      <td>0.288121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050006</td>\n",
       "      <td>0.141967</td>\n",
       "      <td>3.723165</td>\n",
       "      <td>7.102232</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.152511</td>\n",
       "      <td>0.251800</td>\n",
       "      <td>0.261882</td>\n",
       "      <td>0.037246</td>\n",
       "      <td>0.355154</td>\n",
       "      <td>272.316479</td>\n",
       "      <td>610.223243</td>\n",
       "      <td>0.316365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>0.085865</td>\n",
       "      <td>3.468357</td>\n",
       "      <td>5.285295</td>\n",
       "      <td>0.122966</td>\n",
       "      <td>0.109552</td>\n",
       "      <td>0.187383</td>\n",
       "      <td>0.185717</td>\n",
       "      <td>0.173439</td>\n",
       "      <td>0.528593</td>\n",
       "      <td>246.835715</td>\n",
       "      <td>428.529479</td>\n",
       "      <td>0.444334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150005</td>\n",
       "      <td>0.060279</td>\n",
       "      <td>2.197463</td>\n",
       "      <td>4.256201</td>\n",
       "      <td>0.077908</td>\n",
       "      <td>0.071692</td>\n",
       "      <td>0.150898</td>\n",
       "      <td>0.147716</td>\n",
       "      <td>0.109857</td>\n",
       "      <td>0.638450</td>\n",
       "      <td>119.746313</td>\n",
       "      <td>325.620062</td>\n",
       "      <td>0.506399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200011</td>\n",
       "      <td>0.044445</td>\n",
       "      <td>1.617564</td>\n",
       "      <td>3.596497</td>\n",
       "      <td>0.057349</td>\n",
       "      <td>0.051758</td>\n",
       "      <td>0.127509</td>\n",
       "      <td>0.123725</td>\n",
       "      <td>0.080888</td>\n",
       "      <td>0.719338</td>\n",
       "      <td>61.756353</td>\n",
       "      <td>259.649735</td>\n",
       "      <td>0.538416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300009</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>1.068487</td>\n",
       "      <td>2.753865</td>\n",
       "      <td>0.037882</td>\n",
       "      <td>0.035185</td>\n",
       "      <td>0.097635</td>\n",
       "      <td>0.094213</td>\n",
       "      <td>0.106847</td>\n",
       "      <td>0.826185</td>\n",
       "      <td>6.848679</td>\n",
       "      <td>175.386463</td>\n",
       "      <td>0.545516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400008</td>\n",
       "      <td>0.019122</td>\n",
       "      <td>0.639587</td>\n",
       "      <td>2.225313</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.078896</td>\n",
       "      <td>0.076415</td>\n",
       "      <td>0.063958</td>\n",
       "      <td>0.890143</td>\n",
       "      <td>-36.041284</td>\n",
       "      <td>122.531289</td>\n",
       "      <td>0.508151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500007</td>\n",
       "      <td>0.013803</td>\n",
       "      <td>0.406326</td>\n",
       "      <td>1.861525</td>\n",
       "      <td>0.014406</td>\n",
       "      <td>0.016273</td>\n",
       "      <td>0.065998</td>\n",
       "      <td>0.064387</td>\n",
       "      <td>0.040632</td>\n",
       "      <td>0.930775</td>\n",
       "      <td>-59.367404</td>\n",
       "      <td>86.152521</td>\n",
       "      <td>0.446602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600005</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>0.300982</td>\n",
       "      <td>1.601440</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>0.056777</td>\n",
       "      <td>0.055657</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.960873</td>\n",
       "      <td>-69.901781</td>\n",
       "      <td>60.144049</td>\n",
       "      <td>0.374132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700004</td>\n",
       "      <td>0.008107</td>\n",
       "      <td>0.184352</td>\n",
       "      <td>1.399003</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.049024</td>\n",
       "      <td>0.018435</td>\n",
       "      <td>0.979308</td>\n",
       "      <td>-81.564841</td>\n",
       "      <td>39.900307</td>\n",
       "      <td>0.289570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.800003</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>0.105344</td>\n",
       "      <td>1.237298</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>0.043867</td>\n",
       "      <td>0.043795</td>\n",
       "      <td>0.010534</td>\n",
       "      <td>0.989842</td>\n",
       "      <td>-89.465623</td>\n",
       "      <td>23.729836</td>\n",
       "      <td>0.196817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.900001</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>0.060196</td>\n",
       "      <td>1.106511</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.039551</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.995862</td>\n",
       "      <td>-93.980356</td>\n",
       "      <td>10.651119</td>\n",
       "      <td>0.099384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.041385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-95.861495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold       lift  \\\n",
       "0       1                  0.010004         0.344236  13.012273   \n",
       "1       2                  0.020008         0.243068   7.784799   \n",
       "2       3                  0.030012         0.195026   6.054844   \n",
       "3       4                  0.040002         0.163482   4.933190   \n",
       "4       5                  0.050006         0.141967   3.723165   \n",
       "5       6                  0.100012         0.085865   3.468357   \n",
       "6       7                  0.150005         0.060279   2.197463   \n",
       "7       8                  0.200011         0.044445   1.617564   \n",
       "8       9                  0.300009         0.027777   1.068487   \n",
       "9      10                  0.400008         0.019122   0.639587   \n",
       "10     11                  0.500007         0.013803   0.406326   \n",
       "11     12                  0.600005         0.010450   0.300982   \n",
       "12     13                  0.700004         0.008107   0.184352   \n",
       "13     14                  0.800003         0.006342   0.105344   \n",
       "14     15                  0.900001         0.004857   0.060196   \n",
       "15     16                  1.000000         0.002448   0.041385   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0         13.012273       0.461333  0.473428                  0.461333   \n",
       "1         10.398536       0.276000  0.287629                  0.368667   \n",
       "2          8.950639       0.214667  0.217315                  0.317333   \n",
       "3          7.947281       0.174900  0.178416                  0.281761   \n",
       "4          7.102232       0.132000  0.152511                  0.251800   \n",
       "5          5.285295       0.122966  0.109552                  0.187383   \n",
       "6          4.256201       0.077908  0.071692                  0.150898   \n",
       "7          3.596497       0.057349  0.051758                  0.127509   \n",
       "8          2.753865       0.037882  0.035185                  0.097635   \n",
       "9          2.225313       0.022676  0.023018                  0.078896   \n",
       "10         1.861525       0.014406  0.016273                  0.065998   \n",
       "11         1.601440       0.010671  0.012010                  0.056777   \n",
       "12         1.399003       0.006536  0.009223                  0.049600   \n",
       "13         1.237298       0.003735  0.007193                  0.043867   \n",
       "14         1.106511       0.002134  0.005594                  0.039230   \n",
       "15         1.000000       0.001467  0.004046                  0.035454   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate         gain  \\\n",
       "0           0.473428      0.130173                 0.130173  1201.227289   \n",
       "1           0.380528      0.077878                 0.208051   678.479910   \n",
       "2           0.326124      0.060572                 0.268623   505.484374   \n",
       "3           0.289234      0.049285                 0.317908   393.318958   \n",
       "4           0.261882      0.037246                 0.355154   272.316479   \n",
       "5           0.185717      0.173439                 0.528593   246.835715   \n",
       "6           0.147716      0.109857                 0.638450   119.746313   \n",
       "7           0.123725      0.080888                 0.719338    61.756353   \n",
       "8           0.094213      0.106847                 0.826185     6.848679   \n",
       "9           0.076415      0.063958                 0.890143   -36.041284   \n",
       "10          0.064387      0.040632                 0.930775   -59.367404   \n",
       "11          0.055657      0.030098                 0.960873   -69.901781   \n",
       "12          0.049024      0.018435                 0.979308   -81.564841   \n",
       "13          0.043795      0.010534                 0.989842   -89.465623   \n",
       "14          0.039551      0.006020                 0.995862   -93.980356   \n",
       "15          0.036000      0.004138                 1.000000   -95.861495   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0       1201.227289            0.124586  \n",
       "1        939.853599            0.194955  \n",
       "2        795.063858            0.247382  \n",
       "3        694.728102            0.288121  \n",
       "4        610.223243            0.316365  \n",
       "5        428.529479            0.444334  \n",
       "6        325.620062            0.506399  \n",
       "7        259.649735            0.538416  \n",
       "8        175.386463            0.545516  \n",
       "9        122.531289            0.508151  \n",
       "10        86.152521            0.446602  \n",
       "11        60.144049            0.374132  \n",
       "12        39.900307            0.289570  \n",
       "13        23.729836            0.196817  \n",
       "14        10.651119            0.099384  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_auc</th>\n",
       "      <th>validation_pr_auc</th>\n",
       "      <th>validation_lift</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:45</td>\n",
       "      <td>0.033 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186655</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.036147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963853</td>\n",
       "      <td>0.184925</td>\n",
       "      <td>0.153223</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:46</td>\n",
       "      <td>0.702 sec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.184765</td>\n",
       "      <td>0.147793</td>\n",
       "      <td>0.813317</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>8.555719</td>\n",
       "      <td>0.075742</td>\n",
       "      <td>0.183099</td>\n",
       "      <td>0.145890</td>\n",
       "      <td>0.802085</td>\n",
       "      <td>0.169243</td>\n",
       "      <td>8.720747</td>\n",
       "      <td>0.056662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:46</td>\n",
       "      <td>1.112 sec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.183459</td>\n",
       "      <td>0.143542</td>\n",
       "      <td>0.826473</td>\n",
       "      <td>0.187720</td>\n",
       "      <td>8.791581</td>\n",
       "      <td>0.075742</td>\n",
       "      <td>0.181892</td>\n",
       "      <td>0.142011</td>\n",
       "      <td>0.812856</td>\n",
       "      <td>0.173714</td>\n",
       "      <td>8.818929</td>\n",
       "      <td>0.071134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:46</td>\n",
       "      <td>1.246 sec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.182341</td>\n",
       "      <td>0.140210</td>\n",
       "      <td>0.835080</td>\n",
       "      <td>0.198593</td>\n",
       "      <td>10.487783</td>\n",
       "      <td>0.057722</td>\n",
       "      <td>0.180861</td>\n",
       "      <td>0.138954</td>\n",
       "      <td>0.821264</td>\n",
       "      <td>0.183773</td>\n",
       "      <td>10.026278</td>\n",
       "      <td>0.060690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:47</td>\n",
       "      <td>1.364 sec</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.181368</td>\n",
       "      <td>0.137493</td>\n",
       "      <td>0.840208</td>\n",
       "      <td>0.207142</td>\n",
       "      <td>10.765505</td>\n",
       "      <td>0.066426</td>\n",
       "      <td>0.179975</td>\n",
       "      <td>0.136474</td>\n",
       "      <td>0.826905</td>\n",
       "      <td>0.190732</td>\n",
       "      <td>10.490061</td>\n",
       "      <td>0.061837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:47</td>\n",
       "      <td>1.498 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.180583</td>\n",
       "      <td>0.135441</td>\n",
       "      <td>0.841629</td>\n",
       "      <td>0.210621</td>\n",
       "      <td>11.014035</td>\n",
       "      <td>0.065013</td>\n",
       "      <td>0.179279</td>\n",
       "      <td>0.134624</td>\n",
       "      <td>0.828782</td>\n",
       "      <td>0.193185</td>\n",
       "      <td>10.352126</td>\n",
       "      <td>0.062144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:47</td>\n",
       "      <td>1.641 sec</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.133582</td>\n",
       "      <td>0.843628</td>\n",
       "      <td>0.214550</td>\n",
       "      <td>11.119672</td>\n",
       "      <td>0.068339</td>\n",
       "      <td>0.178659</td>\n",
       "      <td>0.133004</td>\n",
       "      <td>0.830120</td>\n",
       "      <td>0.196673</td>\n",
       "      <td>10.577173</td>\n",
       "      <td>0.068053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:47</td>\n",
       "      <td>1.806 sec</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.179205</td>\n",
       "      <td>0.131895</td>\n",
       "      <td>0.846607</td>\n",
       "      <td>0.220035</td>\n",
       "      <td>11.354027</td>\n",
       "      <td>0.064719</td>\n",
       "      <td>0.178059</td>\n",
       "      <td>0.131466</td>\n",
       "      <td>0.832486</td>\n",
       "      <td>0.202264</td>\n",
       "      <td>10.680594</td>\n",
       "      <td>0.059396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:47</td>\n",
       "      <td>1.966 sec</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.178666</td>\n",
       "      <td>0.130545</td>\n",
       "      <td>0.848053</td>\n",
       "      <td>0.223481</td>\n",
       "      <td>11.535026</td>\n",
       "      <td>0.062666</td>\n",
       "      <td>0.177618</td>\n",
       "      <td>0.130322</td>\n",
       "      <td>0.833550</td>\n",
       "      <td>0.203886</td>\n",
       "      <td>10.943848</td>\n",
       "      <td>0.074189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:47</td>\n",
       "      <td>2.162 sec</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.178168</td>\n",
       "      <td>0.129365</td>\n",
       "      <td>0.849110</td>\n",
       "      <td>0.226545</td>\n",
       "      <td>11.638101</td>\n",
       "      <td>0.064982</td>\n",
       "      <td>0.177223</td>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.834014</td>\n",
       "      <td>0.205516</td>\n",
       "      <td>11.102281</td>\n",
       "      <td>0.071534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:47</td>\n",
       "      <td>2.304 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.177741</td>\n",
       "      <td>0.128381</td>\n",
       "      <td>0.850032</td>\n",
       "      <td>0.229742</td>\n",
       "      <td>11.814733</td>\n",
       "      <td>0.061990</td>\n",
       "      <td>0.176867</td>\n",
       "      <td>0.128484</td>\n",
       "      <td>0.835040</td>\n",
       "      <td>0.207781</td>\n",
       "      <td>11.583179</td>\n",
       "      <td>0.071107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:48</td>\n",
       "      <td>2.696 sec</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.177354</td>\n",
       "      <td>0.127381</td>\n",
       "      <td>0.851530</td>\n",
       "      <td>0.232266</td>\n",
       "      <td>11.842942</td>\n",
       "      <td>0.062432</td>\n",
       "      <td>0.176551</td>\n",
       "      <td>0.127627</td>\n",
       "      <td>0.836041</td>\n",
       "      <td>0.209696</td>\n",
       "      <td>11.545572</td>\n",
       "      <td>0.067760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:48</td>\n",
       "      <td>3.219 sec</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.177007</td>\n",
       "      <td>0.126571</td>\n",
       "      <td>0.853317</td>\n",
       "      <td>0.235013</td>\n",
       "      <td>11.909504</td>\n",
       "      <td>0.060123</td>\n",
       "      <td>0.176288</td>\n",
       "      <td>0.126971</td>\n",
       "      <td>0.837513</td>\n",
       "      <td>0.211371</td>\n",
       "      <td>11.545572</td>\n",
       "      <td>0.071681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:49</td>\n",
       "      <td>3.903 sec</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.176689</td>\n",
       "      <td>0.125759</td>\n",
       "      <td>0.854695</td>\n",
       "      <td>0.237217</td>\n",
       "      <td>12.122737</td>\n",
       "      <td>0.060851</td>\n",
       "      <td>0.176049</td>\n",
       "      <td>0.126336</td>\n",
       "      <td>0.838146</td>\n",
       "      <td>0.213103</td>\n",
       "      <td>11.696003</td>\n",
       "      <td>0.068493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2020-09-22 07:25:53</td>\n",
       "      <td>7.663 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.171774</td>\n",
       "      <td>0.115051</td>\n",
       "      <td>0.878193</td>\n",
       "      <td>0.295039</td>\n",
       "      <td>14.286666</td>\n",
       "      <td>0.053128</td>\n",
       "      <td>0.173624</td>\n",
       "      <td>0.119521</td>\n",
       "      <td>0.854117</td>\n",
       "      <td>0.237731</td>\n",
       "      <td>13.012273</td>\n",
       "      <td>0.052153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2020-09-22 07:25:45   0.033 sec              0.0       0.186655   \n",
       "1     2020-09-22 07:25:46   0.702 sec              1.0       0.184765   \n",
       "2     2020-09-22 07:25:46   1.112 sec              2.0       0.183459   \n",
       "3     2020-09-22 07:25:46   1.246 sec              3.0       0.182341   \n",
       "4     2020-09-22 07:25:47   1.364 sec              4.0       0.181368   \n",
       "5     2020-09-22 07:25:47   1.498 sec              5.0       0.180583   \n",
       "6     2020-09-22 07:25:47   1.641 sec              6.0       0.179867   \n",
       "7     2020-09-22 07:25:47   1.806 sec              7.0       0.179205   \n",
       "8     2020-09-22 07:25:47   1.966 sec              8.0       0.178666   \n",
       "9     2020-09-22 07:25:47   2.162 sec              9.0       0.178168   \n",
       "10    2020-09-22 07:25:47   2.304 sec             10.0       0.177741   \n",
       "11    2020-09-22 07:25:48   2.696 sec             11.0       0.177354   \n",
       "12    2020-09-22 07:25:48   3.219 sec             12.0       0.177007   \n",
       "13    2020-09-22 07:25:49   3.903 sec             13.0       0.176689   \n",
       "14    2020-09-22 07:25:53   7.663 sec             50.0       0.171774   \n",
       "\n",
       "    training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0           0.155498      0.500000         0.036147       1.000000   \n",
       "1           0.147793      0.813317         0.179129       8.555719   \n",
       "2           0.143542      0.826473         0.187720       8.791581   \n",
       "3           0.140210      0.835080         0.198593      10.487783   \n",
       "4           0.137493      0.840208         0.207142      10.765505   \n",
       "5           0.135441      0.841629         0.210621      11.014035   \n",
       "6           0.133582      0.843628         0.214550      11.119672   \n",
       "7           0.131895      0.846607         0.220035      11.354027   \n",
       "8           0.130545      0.848053         0.223481      11.535026   \n",
       "9           0.129365      0.849110         0.226545      11.638101   \n",
       "10          0.128381      0.850032         0.229742      11.814733   \n",
       "11          0.127381      0.851530         0.232266      11.842942   \n",
       "12          0.126571      0.853317         0.235013      11.909504   \n",
       "13          0.125759      0.854695         0.237217      12.122737   \n",
       "14          0.115051      0.878193         0.295039      14.286666   \n",
       "\n",
       "    training_classification_error  validation_rmse  validation_logloss  \\\n",
       "0                        0.963853         0.184925            0.153223   \n",
       "1                        0.075742         0.183099            0.145890   \n",
       "2                        0.075742         0.181892            0.142011   \n",
       "3                        0.057722         0.180861            0.138954   \n",
       "4                        0.066426         0.179975            0.136474   \n",
       "5                        0.065013         0.179279            0.134624   \n",
       "6                        0.068339         0.178659            0.133004   \n",
       "7                        0.064719         0.178059            0.131466   \n",
       "8                        0.062666         0.177618            0.130322   \n",
       "9                        0.064982         0.177223            0.129354   \n",
       "10                       0.061990         0.176867            0.128484   \n",
       "11                       0.062432         0.176551            0.127627   \n",
       "12                       0.060123         0.176288            0.126971   \n",
       "13                       0.060851         0.176049            0.126336   \n",
       "14                       0.053128         0.173624            0.119521   \n",
       "\n",
       "    validation_auc  validation_pr_auc  validation_lift  \\\n",
       "0         0.500000           0.035454         1.000000   \n",
       "1         0.802085           0.169243         8.720747   \n",
       "2         0.812856           0.173714         8.818929   \n",
       "3         0.821264           0.183773        10.026278   \n",
       "4         0.826905           0.190732        10.490061   \n",
       "5         0.828782           0.193185        10.352126   \n",
       "6         0.830120           0.196673        10.577173   \n",
       "7         0.832486           0.202264        10.680594   \n",
       "8         0.833550           0.203886        10.943848   \n",
       "9         0.834014           0.205516        11.102281   \n",
       "10        0.835040           0.207781        11.583179   \n",
       "11        0.836041           0.209696        11.545572   \n",
       "12        0.837513           0.211371        11.545572   \n",
       "13        0.838146           0.213103        11.696003   \n",
       "14        0.854117           0.237731        13.012273   \n",
       "\n",
       "    validation_classification_error  \n",
       "0                          0.964546  \n",
       "1                          0.056662  \n",
       "2                          0.071134  \n",
       "3                          0.060690  \n",
       "4                          0.061837  \n",
       "5                          0.062144  \n",
       "6                          0.068053  \n",
       "7                          0.059396  \n",
       "8                          0.074189  \n",
       "9                          0.071534  \n",
       "10                         0.071107  \n",
       "11                         0.067760  \n",
       "12                         0.071681  \n",
       "13                         0.068493  \n",
       "14                         0.052153  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CREDIT_SCORE</td>\n",
       "      <td>2309.658691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SERVICER_NAME</td>\n",
       "      <td>1683.956299</td>\n",
       "      <td>0.729093</td>\n",
       "      <td>0.215026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROPERTY_STATE</td>\n",
       "      <td>1255.222290</td>\n",
       "      <td>0.543467</td>\n",
       "      <td>0.160281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELLER_NAME</td>\n",
       "      <td>997.285217</td>\n",
       "      <td>0.431789</td>\n",
       "      <td>0.127345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUMBER_OF_BORROWERS</td>\n",
       "      <td>316.293396</td>\n",
       "      <td>0.136944</td>\n",
       "      <td>0.040388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORIGINAL_INTEREST_RATE</td>\n",
       "      <td>300.391693</td>\n",
       "      <td>0.130059</td>\n",
       "      <td>0.038357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORIGINAL_UPB</td>\n",
       "      <td>292.308807</td>\n",
       "      <td>0.126559</td>\n",
       "      <td>0.037325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MORTGAGE_INSURANCE_PERCENTAGE</td>\n",
       "      <td>186.016342</td>\n",
       "      <td>0.080538</td>\n",
       "      <td>0.023753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORIGINAL_LOAN_TO_VALUE</td>\n",
       "      <td>158.307068</td>\n",
       "      <td>0.068541</td>\n",
       "      <td>0.020214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PROPERTY_TYPE</td>\n",
       "      <td>64.317169</td>\n",
       "      <td>0.027847</td>\n",
       "      <td>0.008213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORIGINAL_COMBINED_LOAN_TO_VALUE</td>\n",
       "      <td>54.901577</td>\n",
       "      <td>0.023770</td>\n",
       "      <td>0.007010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LOAN_PURPOSE</td>\n",
       "      <td>53.130379</td>\n",
       "      <td>0.023004</td>\n",
       "      <td>0.006784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MATURITY_DATE</td>\n",
       "      <td>46.874786</td>\n",
       "      <td>0.020295</td>\n",
       "      <td>0.005985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ORIGINAL_DEBT_TO_INCOME_RATIO</td>\n",
       "      <td>36.971573</td>\n",
       "      <td>0.016007</td>\n",
       "      <td>0.004721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FIRST_PAYMENT_DATE</td>\n",
       "      <td>25.007473</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.003193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OCCUPANCY_STATUS</td>\n",
       "      <td>21.170610</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.002703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CHANNEL</td>\n",
       "      <td>16.820601</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.002148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>METROPOLITAN_STATISTICAL_AREA</td>\n",
       "      <td>11.293387</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.001442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FIRST_TIME_HOMEBUYER_FLAG</td>\n",
       "      <td>1.468417</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NUMBER_OF_UNITS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           variable  relative_importance  scaled_importance  \\\n",
       "0                      CREDIT_SCORE          2309.658691           1.000000   \n",
       "1                     SERVICER_NAME          1683.956299           0.729093   \n",
       "2                    PROPERTY_STATE          1255.222290           0.543467   \n",
       "3                       SELLER_NAME           997.285217           0.431789   \n",
       "4               NUMBER_OF_BORROWERS           316.293396           0.136944   \n",
       "5            ORIGINAL_INTEREST_RATE           300.391693           0.130059   \n",
       "6                      ORIGINAL_UPB           292.308807           0.126559   \n",
       "7     MORTGAGE_INSURANCE_PERCENTAGE           186.016342           0.080538   \n",
       "8            ORIGINAL_LOAN_TO_VALUE           158.307068           0.068541   \n",
       "9                     PROPERTY_TYPE            64.317169           0.027847   \n",
       "10  ORIGINAL_COMBINED_LOAN_TO_VALUE            54.901577           0.023770   \n",
       "11                     LOAN_PURPOSE            53.130379           0.023004   \n",
       "12                    MATURITY_DATE            46.874786           0.020295   \n",
       "13    ORIGINAL_DEBT_TO_INCOME_RATIO            36.971573           0.016007   \n",
       "14               FIRST_PAYMENT_DATE            25.007473           0.010827   \n",
       "15                 OCCUPANCY_STATUS            21.170610           0.009166   \n",
       "16                          CHANNEL            16.820601           0.007283   \n",
       "17    METROPOLITAN_STATISTICAL_AREA            11.293387           0.004890   \n",
       "18        FIRST_TIME_HOMEBUYER_FLAG             1.468417           0.000636   \n",
       "19                  NUMBER_OF_UNITS             0.000000           0.000000   \n",
       "\n",
       "    percentage  \n",
       "0     0.294923  \n",
       "1     0.215026  \n",
       "2     0.160281  \n",
       "3     0.127345  \n",
       "4     0.040388  \n",
       "5     0.038357  \n",
       "6     0.037325  \n",
       "7     0.023753  \n",
       "8     0.020214  \n",
       "9     0.008213  \n",
       "10    0.007010  \n",
       "11    0.006784  \n",
       "12    0.005985  \n",
       "13    0.004721  \n",
       "14    0.003193  \n",
       "15    0.002703  \n",
       "16    0.002148  \n",
       "17    0.001442  \n",
       "18    0.000188  \n",
       "19    0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The default GBM model had a slightly better performance than the default GLM. We will make the predictions with the GBM model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">   FALSE</th><th style=\"text-align: right;\">      TRUE</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.978372</td><td style=\"text-align: right;\">0.0216281 </td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.995024</td><td style=\"text-align: right;\">0.00497636</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.964645</td><td style=\"text-align: right;\">0.0353549 </td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.99305 </td><td style=\"text-align: right;\">0.00694996</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.99217 </td><td style=\"text-align: right;\">0.0078297 </td></tr>\n",
       "<tr><td>TRUE     </td><td style=\"text-align: right;\">0.591272</td><td style=\"text-align: right;\">0.408728  </td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.993899</td><td style=\"text-align: right;\">0.00610064</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.995599</td><td style=\"text-align: right;\">0.00440117</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.950489</td><td style=\"text-align: right;\">0.0495107 </td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.992925</td><td style=\"text-align: right;\">0.00707464</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.predict(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once again, save the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "default_gbm_per = gbm.model_performance(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, we will tune our models and see if we can achieve better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Print the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tune the GBM model with H2O GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n",
      "CPU times: user 896 ms, sys: 84 ms, total: 980 ms\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "hyper_params = {'max_depth' : [3,4,5,6,7,8,9,10,12,13,15],\n",
    "               }\n",
    "\n",
    "gbm = H2OGradientBoostingEstimator(model_id='grid_gbm', ntrees=50,\n",
    "    seed=42\n",
    "    )\n",
    "\n",
    "gbm_grid = H2OGridSearch(gbm, hyper_params,\n",
    "                         grid_id = 'depth_gbm_grid',\n",
    "                         search_criteria = {\n",
    "                             \"strategy\":\"Cartesian\"})\n",
    "\n",
    "%time gbm_grid.train(x=x, y=y, training_frame=train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>model_ids</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>depth_gbm_grid_model_4</td>\n",
       "      <td>0.8545923078708804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>depth_gbm_grid_model_3</td>\n",
       "      <td>0.8541170986087288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>depth_gbm_grid_model_5</td>\n",
       "      <td>0.8528663309115709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>depth_gbm_grid_model_6</td>\n",
       "      <td>0.8513605529560967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>depth_gbm_grid_model_2</td>\n",
       "      <td>0.8511981455252366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>depth_gbm_grid_model_7</td>\n",
       "      <td>0.8497735374676534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>depth_gbm_grid_model_1</td>\n",
       "      <td>0.8476401398039958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>depth_gbm_grid_model_8</td>\n",
       "      <td>0.8450226310613556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>depth_gbm_grid_model_9</td>\n",
       "      <td>0.8346136315461742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>depth_gbm_grid_model_10</td>\n",
       "      <td>0.8323082222705518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>depth_gbm_grid_model_11</td>\n",
       "      <td>0.8259738486160672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth                model_ids                 auc\n",
       "0            6   depth_gbm_grid_model_4  0.8545923078708804\n",
       "1            5   depth_gbm_grid_model_3  0.8541170986087288\n",
       "2            7   depth_gbm_grid_model_5  0.8528663309115709\n",
       "3            8   depth_gbm_grid_model_6  0.8513605529560967\n",
       "4            4   depth_gbm_grid_model_2  0.8511981455252366\n",
       "5            9   depth_gbm_grid_model_7  0.8497735374676534\n",
       "6            3   depth_gbm_grid_model_1  0.8476401398039958\n",
       "7           10   depth_gbm_grid_model_8  0.8450226310613556\n",
       "8           12   depth_gbm_grid_model_9  0.8346136315461742\n",
       "9           13  depth_gbm_grid_model_10  0.8323082222705518\n",
       "10          15  depth_gbm_grid_model_11  0.8259738486160672"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_gbm_depth = gbm_grid.get_grid(sort_by='auc',decreasing=True)\n",
    "sorted_gbm_depth.sorted_metric_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n",
      "CPU times: user 5.86 s, sys: 655 ms, total: 6.51 s\n",
      "Wall time: 15min 3s\n"
     ]
    }
   ],
   "source": [
    "gbm = H2OGradientBoostingEstimator(\n",
    "    ntrees=500,\n",
    "    learn_rate=0.05,\n",
    "    seed=42,\n",
    "    model_id='grid_gbm'\n",
    "    )\n",
    "\n",
    "hyper_params_tune = {\n",
    "                'max_depth' : [4, 5, 6, 7, 8],\n",
    "                'sample_rate': [x/100. for x in range(20,101)],\n",
    "                'col_sample_rate' : [x/100. for x in range(20,101)],\n",
    "                'col_sample_rate_per_tree': [x/100. for x in range(20,101)],\n",
    "                'col_sample_rate_change_per_level': [x/100. for x in range(90,111)],\n",
    "}\n",
    "\n",
    "search_criteria_tune = {'strategy': \"RandomDiscrete\",\n",
    "                   'max_runtime_secs': 900,  \n",
    "                   'max_models': 100,  ## build no more than 100 models\n",
    "                   'seed' : 42 }\n",
    "\n",
    "random_grid = H2OGridSearch(model=gbm, hyper_params=hyper_params_tune,\n",
    "                         grid_id = 'random_grid',\n",
    "                         search_criteria =search_criteria_tune)\n",
    "\n",
    "%time random_grid.train(x=x, y=y, training_frame=train, validation_frame = valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>col_sample_rate</th>\n",
       "      <th>col_sample_rate_change_per_level</th>\n",
       "      <th>col_sample_rate_per_tree</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>model_ids</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.99</td>\n",
       "      <td>random_grid_model_30</td>\n",
       "      <td>0.8620868754474125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.23</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>random_grid_model_25</td>\n",
       "      <td>0.8617075128951219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.72</td>\n",
       "      <td>random_grid_model_21</td>\n",
       "      <td>0.8614973967206373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.33</td>\n",
       "      <td>5</td>\n",
       "      <td>0.48</td>\n",
       "      <td>random_grid_model_32</td>\n",
       "      <td>0.8610029010558012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8</td>\n",
       "      <td>0.82</td>\n",
       "      <td>random_grid_model_15</td>\n",
       "      <td>0.8609132611650401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.59</td>\n",
       "      <td>random_grid_model_5</td>\n",
       "      <td>0.8608263943124851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.28</td>\n",
       "      <td>random_grid_model_26</td>\n",
       "      <td>0.8606680892092531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>random_grid_model_17</td>\n",
       "      <td>0.8605897261671075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.64</td>\n",
       "      <td>7</td>\n",
       "      <td>0.71</td>\n",
       "      <td>random_grid_model_19</td>\n",
       "      <td>0.8602606945183965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.77</td>\n",
       "      <td>6</td>\n",
       "      <td>0.71</td>\n",
       "      <td>random_grid_model_20</td>\n",
       "      <td>0.8601995498063519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.61</td>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>random_grid_model_31</td>\n",
       "      <td>0.8601630398708682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>random_grid_model_18</td>\n",
       "      <td>0.8600038685183653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.41</td>\n",
       "      <td>6</td>\n",
       "      <td>0.26</td>\n",
       "      <td>random_grid_model_27</td>\n",
       "      <td>0.8598680182610965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.54</td>\n",
       "      <td>7</td>\n",
       "      <td>0.58</td>\n",
       "      <td>random_grid_model_24</td>\n",
       "      <td>0.8597800120176088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.65</td>\n",
       "      <td>7</td>\n",
       "      <td>0.71</td>\n",
       "      <td>random_grid_model_22</td>\n",
       "      <td>0.8596179505661873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.77</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>random_grid_model_11</td>\n",
       "      <td>0.8595438095137311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.82</td>\n",
       "      <td>random_grid_model_1</td>\n",
       "      <td>0.859255072763534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.39</td>\n",
       "      <td>random_grid_model_13</td>\n",
       "      <td>0.8592342905850816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.81</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54</td>\n",
       "      <td>random_grid_model_34</td>\n",
       "      <td>0.859159400344067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>7</td>\n",
       "      <td>0.68</td>\n",
       "      <td>random_grid_model_8</td>\n",
       "      <td>0.8591356448235228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>random_grid_model_12</td>\n",
       "      <td>0.8589986889928604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.38</td>\n",
       "      <td>random_grid_model_6</td>\n",
       "      <td>0.8588122008728108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>random_grid_model_28</td>\n",
       "      <td>0.8587718721567579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.51</td>\n",
       "      <td>8</td>\n",
       "      <td>0.54</td>\n",
       "      <td>random_grid_model_3</td>\n",
       "      <td>0.858735859078964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.81</td>\n",
       "      <td>random_grid_model_16</td>\n",
       "      <td>0.8585937811918023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.26</td>\n",
       "      <td>6</td>\n",
       "      <td>0.82</td>\n",
       "      <td>random_grid_model_14</td>\n",
       "      <td>0.8583176635863883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>random_grid_model_33</td>\n",
       "      <td>0.8580090525285962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.51</td>\n",
       "      <td>random_grid_model_7</td>\n",
       "      <td>0.8574747432148412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "      <td>7</td>\n",
       "      <td>0.51</td>\n",
       "      <td>random_grid_model_4</td>\n",
       "      <td>0.8570990641729633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.46</td>\n",
       "      <td>random_grid_model_29</td>\n",
       "      <td>0.8561985837485164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>8</td>\n",
       "      <td>0.96</td>\n",
       "      <td>random_grid_model_2</td>\n",
       "      <td>0.8559221149609657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.79</td>\n",
       "      <td>random_grid_model_9</td>\n",
       "      <td>0.8553069323031242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.88</td>\n",
       "      <td>8</td>\n",
       "      <td>0.51</td>\n",
       "      <td>random_grid_model_23</td>\n",
       "      <td>0.8550951356570811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.87</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>random_grid_model_10</td>\n",
       "      <td>0.8534449255934539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td></td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>7</td>\n",
       "      <td>0.39</td>\n",
       "      <td>random_grid_model_35</td>\n",
       "      <td>0.8331592432433883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     col_sample_rate col_sample_rate_change_per_level  \\\n",
       "0               0.33                             1.01   \n",
       "1               0.63                             0.91   \n",
       "2               0.63                             0.97   \n",
       "3               0.79                             0.93   \n",
       "4               0.53                              0.9   \n",
       "5               0.74                              1.0   \n",
       "6               0.82                             0.98   \n",
       "7               0.26                             0.98   \n",
       "8               0.42                             1.09   \n",
       "9               0.88                             0.92   \n",
       "10              0.54                             0.93   \n",
       "11              0.94                             0.93   \n",
       "12              0.68                             0.97   \n",
       "13              0.53                             0.96   \n",
       "14              0.97                              0.9   \n",
       "15              0.22                             0.98   \n",
       "16              0.28                             1.09   \n",
       "17              0.56                             1.02   \n",
       "18               0.7                             1.08   \n",
       "19              0.22                             1.02   \n",
       "20              0.22                             0.92   \n",
       "21              0.88                             0.95   \n",
       "22              0.46                             1.09   \n",
       "23              0.94                             0.97   \n",
       "24              0.33                             0.98   \n",
       "25              0.25                             1.08   \n",
       "26              0.81                             1.06   \n",
       "27               0.5                              0.9   \n",
       "28               1.0                             0.94   \n",
       "29              0.79                             0.92   \n",
       "30              0.62                             1.02   \n",
       "31               0.6                             1.06   \n",
       "32              0.79                             0.98   \n",
       "33               0.8                              0.9   \n",
       "34              0.54                             0.98   \n",
       "\n",
       "   col_sample_rate_per_tree max_depth sample_rate             model_ids  \\\n",
       "0                      0.38         7        0.99  random_grid_model_30   \n",
       "1                      0.23         6         0.6  random_grid_model_25   \n",
       "2                      0.35         7        0.72  random_grid_model_21   \n",
       "3                      0.33         5        0.48  random_grid_model_32   \n",
       "4                      0.58         8        0.82  random_grid_model_15   \n",
       "5                      0.31         5        0.59   random_grid_model_5   \n",
       "6                      0.26         5        0.28  random_grid_model_26   \n",
       "7                      0.71         5         0.7  random_grid_model_17   \n",
       "8                      0.64         7        0.71  random_grid_model_19   \n",
       "9                      0.77         6        0.71  random_grid_model_20   \n",
       "10                     0.61         5        0.88  random_grid_model_31   \n",
       "11                     0.39         5         0.6  random_grid_model_18   \n",
       "12                     0.41         6        0.26  random_grid_model_27   \n",
       "13                     0.54         7        0.58  random_grid_model_24   \n",
       "14                     0.65         7        0.71  random_grid_model_22   \n",
       "15                     0.77         5         1.0  random_grid_model_11   \n",
       "16                      0.9         7        0.82   random_grid_model_1   \n",
       "17                      0.6         7        0.39  random_grid_model_13   \n",
       "18                     0.81         6        0.54  random_grid_model_34   \n",
       "19                     0.29         7        0.68   random_grid_model_8   \n",
       "20                     0.87         5         0.9  random_grid_model_12   \n",
       "21                      0.2         7        0.38   random_grid_model_6   \n",
       "22                     0.42         8        0.38  random_grid_model_28   \n",
       "23                     0.51         8        0.54   random_grid_model_3   \n",
       "24                     0.26         7        0.81  random_grid_model_16   \n",
       "25                     0.26         6        0.82  random_grid_model_14   \n",
       "26                     0.54         8         0.4  random_grid_model_33   \n",
       "27                     0.21         4        0.51   random_grid_model_7   \n",
       "28                     0.87         7        0.51   random_grid_model_4   \n",
       "29                      1.0         7        0.46  random_grid_model_29   \n",
       "30                     0.95         8        0.96   random_grid_model_2   \n",
       "31                      0.9         8        0.79   random_grid_model_9   \n",
       "32                     0.88         8        0.51  random_grid_model_23   \n",
       "33                     0.87         7         0.2  random_grid_model_10   \n",
       "34                     0.97         7        0.39  random_grid_model_35   \n",
       "\n",
       "                   auc  \n",
       "0   0.8620868754474125  \n",
       "1   0.8617075128951219  \n",
       "2   0.8614973967206373  \n",
       "3   0.8610029010558012  \n",
       "4   0.8609132611650401  \n",
       "5   0.8608263943124851  \n",
       "6   0.8606680892092531  \n",
       "7   0.8605897261671075  \n",
       "8   0.8602606945183965  \n",
       "9   0.8601995498063519  \n",
       "10  0.8601630398708682  \n",
       "11  0.8600038685183653  \n",
       "12  0.8598680182610965  \n",
       "13  0.8597800120176088  \n",
       "14  0.8596179505661873  \n",
       "15  0.8595438095137311  \n",
       "16   0.859255072763534  \n",
       "17  0.8592342905850816  \n",
       "18   0.859159400344067  \n",
       "19  0.8591356448235228  \n",
       "20  0.8589986889928604  \n",
       "21  0.8588122008728108  \n",
       "22  0.8587718721567579  \n",
       "23   0.858735859078964  \n",
       "24  0.8585937811918023  \n",
       "25  0.8583176635863883  \n",
       "26  0.8580090525285962  \n",
       "27  0.8574747432148412  \n",
       "28  0.8570990641729633  \n",
       "29  0.8561985837485164  \n",
       "30  0.8559221149609657  \n",
       "31  0.8553069323031242  \n",
       "32  0.8550951356570811  \n",
       "33  0.8534449255934539  \n",
       "34  0.8331592432433883  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_random_search = random_grid.get_grid(sort_by='auc',decreasing=True)\n",
    "sorted_random_search.sorted_metric_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "We will now print the AUC and F1 scores to see how the model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>344586.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>45.198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0              500.0                     500.0             344586.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        0.0        7.0       3.492         1.0       128.0       45.198  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_gbm = sorted_random_search.models[0]\n",
    "tuned_gbm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8620868754474125\n",
      "[[0.16371106543078953, 0.31935320869125816]]\n"
     ]
    }
   ],
   "source": [
    "tuned_gbm_per = tuned_gbm.model_performance(valid)\n",
    "print(tuned_gbm_per.auc())\n",
    "print(tuned_gbm_per.F1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We were able to get the highest validation AUC among the three models with our GBM. The model reached a 0.8621 AUC, while also improving the F1 to 0.3194.\n",
    "\n",
    "Let's take a look at the confusion matrix and see how are the misclassification errors from this model look like:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.16371106543078953: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>69982.0</td>\n",
       "      <td>2331.0</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>(2331.0/72313.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>(1710.0/2658.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>71692.0</td>\n",
       "      <td>3279.0</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>(4041.0/74971.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FALSE    TRUE   Error               Rate\n",
       "0  FALSE  69982.0  2331.0  0.0322   (2331.0/72313.0)\n",
       "1   TRUE   1710.0   948.0  0.6433    (1710.0/2658.0)\n",
       "2  Total  71692.0  3279.0  0.0539   (4041.0/74971.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_gbm_per.confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Even though the misclassification error for the TRUE class improved, the error for the FALSE class and the overall error did not improve. However, with the tuning that we did, our GBM model was able to make more correct predictions for the TRUE class, which is good since we are dealing with a highly imbalanced dataset.\n",
    "\n",
    "Here is how you can compare the AUC from the default model with the tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GBM AUC: 0.8541 \n",
      "Tuned GBM AUC:0.8621\n"
     ]
    }
   ],
   "source": [
    "print(\"Default GBM AUC: %.4f \\nTuned GBM AUC:%.4f\" % (default_gbm_per.auc(), tuned_gbm_per.auc()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test Set Performance\n",
    "We are going to obtain the test performance of each of the best models. If you named your models the same as in this tutorial, then you should be able to just run the following code. Notice that we are just taking the best models and checking the model performance with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "glm_test_per = tuned_glm.model_performance(test)\n",
    "gbm_test_per = tuned_gbm.model_performance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Print the test AUC of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLM Test AUC: 0.8549 \n",
      "GBM Test AUC: 0.8646 \n"
     ]
    }
   ],
   "source": [
    "print(\"GLM Test AUC: %.4f \\nGBM Test AUC: %.4f \" % \n",
    "      (glm_test_per.auc(), gbm_test_per.auc()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Shut down Cluster\n",
    "Once you are done with the tutorial, remember to shut down the cluster, unless you want to try the challenge after this task, in which case you can shut it down after you are done with the challenge.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "678px",
    "left": "247px",
    "top": "0px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
